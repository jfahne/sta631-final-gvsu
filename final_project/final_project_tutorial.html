<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Joseph Fahnestock" />

<meta name="date" content="2023-04-27" />

<meta name="progressive" content="false" />
<meta name="allow-skip" content="false" />
<meta name="learnr-version-prerender" content="0.11.3" />

<title>STA 631 - Final Project Tutorial</title>

<!-- header-includes START -->
<!-- HEAD_CONTENT -->
<!-- header-includes END -->
<!-- HEAD_CONTENT -->

<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>


<!-- taken from https://github.com/rstudio/rmarkdown/blob/de8a9c38618903627ca509f5401d50a0876079f7/inst/rmd/h/default.html#L293-L343 -->
<!-- tabsets -->
<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>
<!-- end tabsets -->


</head>

<body>
<a class='sr-only sr-only-focusable visually-hidden-focusable' href='#learnr-tutorial-content'>Skip to Tutorial Content</a>



<div class="pageContent band">
<main class="bandContent page">

<article class="topics" id="learnr-tutorial-content">

<div id="section-so-you-took-a-class-with-bradford"
class="section level2">
<h2>So You Took A Class With Bradford?</h2>
<p>You made a wise choice. The freedom to learn in ways that suit you
best is what has made the courses I have taken with Bradford some of my
favorites at GVSU. It is difficult to know as you plan for the end of a
semester what a satisfactory project could look like. What does it mean
to demonstrate the course objectives? How do you take these little
chunks of knowledge you have mined and refine that into a finished
product? Most importantly, what will you wear?</p>
<p><img src="https://www.youtube.com/watch?v=oYhlpV8g2Pc" /></p>
</div>
<div id="section-concocting-a-project" class="section level2">
<h2>Concocting A Project</h2>
<div id="section-where-to-start" class="section level3">
<h3>Where To Start</h3>
<p>While the stated purpose of this end of semester project is to
demonstrate mastery of the course objectives, my approach is to start
with a question I want to answer. Question in hand, I then reflect on
whether the tools I am expected to understand are suited to answering my
question. In the case of this course as taught in Winter 2023, the
course objectives include:</p>
<ul>
<li>Describe probability as a foundation of statistical modeling,
including inference and maximum likelihood estimation</li>
<li>Determine and apply the appropriate generalized linear model for a
specific data context</li>
<li>Conduct model selection for a set of candidate models</li>
<li>Communicate the results of statistical models to a general
audience</li>
<li>Use programming software (i.e., R) to fit and assess statistical
models</li>
</ul>
<p>We would be looking for questions which lend themselves well to
Generalized Linear Models. This is a <em>broad</em> family of models, so
most questions are going to be on the table. The important caveat is
even with an interesting question and a rough idea of how you can use
the required tools, you still need sufficient data.</p>
</div>
<div id="section-data-sourcing" class="section level3">
<h3>Data Sourcing</h3>
<p>“The journey of one-thousand records begins with <del>a single</del>
several queries.”</p>
<p>It is unlikely that you will find the exact data you want on the
first try or in a single, neatly packaged repository. You may need to
pull data from multiple sources and will almost certainly have to
preprocess your data. Why bother with this when you could find neatly
packaged datasets all over the internet?</p>
<p>If you find yourself working with data that you did not need to
preprocess, you are probably not answering a very original question. I
would love to see what you might be able to contribute to the wealth of
analyses on Titanic data. The reason to ask questions which require
elbow grease to find data for is that in preprocessing, you will spend a
great deal of time coming to understand your data and the models you are
investigating. Checking that your data satisfies model assumptions and
that any kinds of test, validate, and train splits you construct are
appropriate are great ways to communicate the understanding required by
the course objectives.</p>
<p>Assuming you agree, even begrudgingly, you might wonder where you
could find data? This depends on your question but here are some great
resources:</p>
<ul>
<li><a href="www.kaggle.com/datasets">Kaggle</a> - Good for finding less
raw data or looking at data sources used to generate the datasets</li>
<li><a href="https://data.gov/">US Gov Data</a> - A huge directory of
government produced data</li>
<li><a href="https://www.opendatanetwork.com/">Open Data Network</a> - A
nice search engine for opensource datasets</li>
</ul>
<p>You can find data all over the place, but I like the above resources
as a starting point for their generality and ease of use.</p>
</div>
</div>
<div id="section-example-project-idea" class="section level2">
<h2>Example Project Idea</h2>
<div id="section-concoting-an-example-project" class="section level3">
<h3>Concoting An Example Project</h3>
<p>Allow me to peel back the curtain a bit and explain that this
tutorial is itself a final project for Bradford’s STA 631 course.
Extremely meta, I know. I was following the same process I shared and my
initial question was, “How likely am I to have unsubscribed from an
email list after I am no longer interested in it?” I have had the same
gmail account since 2010 (<a href="mailto:joeyfahnestock@gmail.com"
class="email">joeyfahnestock@gmail.com</a> hit me up with cat memes) and
it currently has over 46,414 unread messages. I am not an inbox zero
person. Pulling down and working with such a large dataset proved
difficult. There was a lot of text processing and it seemed that the
gigabytes of email data was a little much for my machine. I decided
instead that I would make a tutorial on creating a project to learn more
about <code>learnr</code> and to engage with the course community.</p>
<p>To add a layer to the metatextual nature of this document, my example
project will answer the question, “What data do people analyze?”</p>
</div>
<div id="section-data-sourcing-1" class="section level3">
<h3>Data Sourcing</h3>
<p>“What data do people analyze?” is an extremely broad question which
leads to an important aspect of creating a final project. The question
you start with needs to be iterated on to enable you to answer it.
Ideally, you start with a broad question and fight reality to maintain
the original scope of the question, only qualifying it when necessary.
It would be a lengthy task trying to source enough analyses and datasets
to answer the broad form of this question. I will make the small
qualification that I want to know, “What data do people create datasets
on Kaggle to analyze?”</p>
<p>This is still a broad question with rich paths to investigate, but
data sourcing is now much more straightforward. <a
href="https://www.kaggle.com/docs/api">Kaggle has a great API for
developers to interface with</a> According to Kaggle there are 215,260
public datasets. The Kaggle API returns 20 records per call, so I wrote
this small python script to convert the <a
href="https://en.wikipedia.org/wiki/Pagination#In_web_browsers">paginated</a>
data into one big CSV. In tinkering, I discovered that Kaggle maxes out
the pages you can view from their server side code to 500. Their API
also lets you sort the datasets by some predefined metrics, and I
decided to sort by the most upvoted as these are likely the most
analyzed datasets on Kaggle.</p>
<pre class="python"><code>import pandas as pd
import kaggle
kaggle.api.authenticate()
print(&quot;API REQUESTS BEGINNING&quot;)
try:
    for i in range(1, 501):
        for dataset in kaggle.api.dataset_list(page = i, sort_by=&quot;votes&quot;):
            datasets.append(dataset)
except kaggle.rest.ApiException:
    print(len(datasets)//20)
fields = [
            &#39;ref&#39;, &#39;title&#39;, &#39;size&#39;, &#39;lastUpdated&#39;, &#39;downloadCount&#39;,
            &#39;voteCount&#39;, &#39;usabilityRating&#39;
        ]
print(&quot;API REQUESTS COMPLETE&quot;)
print(&quot;DATAFRAME CREATION&quot;)
dataset_fp = pd.DataFrame([[getattr(i, f) for f in fields] for i in datasets], columns=fields)
print(&quot;DATAFRAME CREATED&quot;)
print(&quot;WRITE OUT&quot;)
dataset_fp.to_csv(&quot;kaggle.csv.zip&quot;, index=None, compression=&quot;zip&quot;)
print(&quot;WRITE COMPLETE&quot;)
print(&quot;Goodbye!&quot;)</code></pre>
<p>We can read the data into R and take a peek at the data which will
<em>NEED</em> some preprocessing.</p>
<pre class="r"><code>library(&quot;readr&quot;)
kaggle_data_raw = read_csv(&quot;kaggle.csv.zip&quot;)
head(kaggle_data_raw)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["ref"],"name":[1],"type":["chr"],"align":["left"]},{"label":["title"],"name":[2],"type":["chr"],"align":["left"]},{"label":["size"],"name":[3],"type":["chr"],"align":["left"]},{"label":["lastUpdated"],"name":[4],"type":["dttm"],"align":["right"]},{"label":["downloadCount"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["voteCount"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["usabilityRating"],"name":[7],"type":["dbl"],"align":["right"]}],"data":[{"1":"jessicali9530/animal-crossing-new-horizons-nookplaza-dataset","2":"Animal Crossing New Horizons Catalog","3":"577KB","4":"2021-06-08 15:05:09","5":"39567","6":"31287","7":"0.8235294"},{"1":"allen-institute-for-ai/CORD-19-research-challenge","2":"COVID-19 Open Research Dataset Challenge (CORD-19)","3":"18GB","4":"2022-06-06 19:39:40","5":"159879","6":"10400","7":"0.8823530"},{"1":"mlg-ulb/creditcardfraud","2":"Credit Card Fraud Detection","3":"66MB","4":"2018-03-23 01:17:27","5":"522136","6":"10088","7":"0.8529412"},{"1":"shivamb/netflix-shows","2":"Netflix Movies and TV Shows","3":"1MB","4":"2021-09-27 04:44:36","5":"332285","6":"7452","7":"1.0000000"},{"1":"sudalairajkumar/novel-corona-virus-2019-dataset","2":"Novel Corona Virus 2019 Dataset","3":"9MB","4":"2021-06-24 04:27:25","5":"404054","6":"5977","7":"0.9705882"},{"1":"paultimothymooney/chest-xray-pneumonia","2":"Chest X-Ray Images (Pneumonia)","3":"2GB","4":"2018-03-24 19:41:59","5":"220969","6":"5651","7":"0.7500000"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>With nearly, ten thousands rows there is bound to be something
interesting to find. The <code>ref</code> column seems to just be the
username and dataset title combined, so we can probably drop that column
and the other columns will need to be processed to be more usable in an
analysis.</p>
</div>
</div>
<div
id="section-creating-a-plan-to-align-your-project-with-course-objectives"
class="section level2">
<h2>Creating A Plan To Align Your Project With Course Objectives</h2>
<p>In general, the ideal way to construct a project is to discuss:</p>
<ul>
<li>The motivating question in an introduction</li>
<li>The sources you used to produce the data</li>
<li>Cleaning conducted on the data</li>
<li>Exploratory analyses</li>
<li>Modeling steps</li>
<li>A conclusion that answers your question</li>
</ul>
<p>This is better practice than listing out the individual course
objectives and trying to hit each of them individually. Adding a
reflection to your project report would allow you to point out the
specific portions of your work that show you have met the objectives.
This being a project within a project about how to do projects allows me
some wiggle room to gracefully point out how I am meeting the course
objectives without needing a reflection.</p>
<div id="section-the-plan" class="section level3">
<h3>The Plan</h3>
<p>The above is a good skeleton for a project report, but the actual
process of analysis is more of an iterative loop:</p>
<ul>
<li>Explore the data and make a hypothesis</li>
<li>Model the data to test our hypothesis</li>
<li>Reflect on whether the model provides a believable answer to our
question</li>
</ul>
<p>These steps encapsulate a messier combination of cleaning, analyzing,
testing, and reworking our question when needed. I am going to pare away
some of these less fruitful iterations I went through for the sake of
brevity and show three iterations for my example project, but take my
word that depending on how you count it I went through dozens.</p>
</div>
</div>
<div id="section-example-project-iteration-0" class="section level2">
<h2>Example Project: Iteration 0</h2>
<div id="section-exploring-uncharted-territory" class="section level3">
<h3>Exploring Uncharted Territory</h3>
<p>With our plan in hand, let’s start with the more obvious
preprocessing steps and exploratory analyses. For a refresher our data
looks like this:</p>
<pre class="r"><code>head(kaggle_data_raw)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["ref"],"name":[1],"type":["chr"],"align":["left"]},{"label":["title"],"name":[2],"type":["chr"],"align":["left"]},{"label":["size"],"name":[3],"type":["chr"],"align":["left"]},{"label":["lastUpdated"],"name":[4],"type":["dttm"],"align":["right"]},{"label":["downloadCount"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["voteCount"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["usabilityRating"],"name":[7],"type":["dbl"],"align":["right"]}],"data":[{"1":"jessicali9530/animal-crossing-new-horizons-nookplaza-dataset","2":"Animal Crossing New Horizons Catalog","3":"577KB","4":"2021-06-08 15:05:09","5":"39567","6":"31287","7":"0.8235294"},{"1":"allen-institute-for-ai/CORD-19-research-challenge","2":"COVID-19 Open Research Dataset Challenge (CORD-19)","3":"18GB","4":"2022-06-06 19:39:40","5":"159879","6":"10400","7":"0.8823530"},{"1":"mlg-ulb/creditcardfraud","2":"Credit Card Fraud Detection","3":"66MB","4":"2018-03-23 01:17:27","5":"522136","6":"10088","7":"0.8529412"},{"1":"shivamb/netflix-shows","2":"Netflix Movies and TV Shows","3":"1MB","4":"2021-09-27 04:44:36","5":"332285","6":"7452","7":"1.0000000"},{"1":"sudalairajkumar/novel-corona-virus-2019-dataset","2":"Novel Corona Virus 2019 Dataset","3":"9MB","4":"2021-06-24 04:27:25","5":"404054","6":"5977","7":"0.9705882"},{"1":"paultimothymooney/chest-xray-pneumonia","2":"Chest X-Ray Images (Pneumonia)","3":"2GB","4":"2018-03-24 19:41:59","5":"220969","6":"5651","7":"0.7500000"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>We need to have the data in a format that’s usable and we do not need
to retain duplicate data. We can see that some needed steps include:</p>
<ul>
<li><code>ref</code> can be dropped as it duplicates the
<code>title</code> column</li>
<li><code>title</code> will have only alphanumeric characters retained
and making all letters lowercase to standardize the strings</li>
<li><code>size</code> needs to be converted to a standard unit of bytes
so that the column can just be an integer rather than a string</li>
<li><code>lastUpdated</code> can be converted from a datetime object to
how many days before the date they were accessed (April 27, 2023) so we
have a column of integers</li>
<li><code>downloadCount</code>, <code>voteCount</code>, and
<code>usabilityRating</code> will be left alone until we do some
exploration</li>
</ul>
<pre class="r"><code>library(dplyr) # Grammar for data transformation
library(stringr) # String manipulation tool
library(lubridate) # Datetime convenience library

unique(str_replace_all(kaggle_data_raw$size, &quot;[^\\P{Nd}]&quot;, &quot;&quot;)) # Show how big files can get</code></pre>
<pre><code>## [1] &quot;KB&quot; &quot;GB&quot; &quot;MB&quot; &quot;B&quot;</code></pre>
<pre class="r"><code>kaggle_cleaned = kaggle_data_raw %&gt;% 
  select(-ref) %&gt;% 
  mutate(title = str_remove_all(title, &quot;[^[:alnum:]^[:space:]]&quot;) %&gt;% tolower()) %&gt;% 
  mutate(size = case_when(
    str_detect(size, &quot;KB$&quot;) ~ str_replace(size, &quot;KB$&quot;, &quot;&quot;) %&gt;% as.numeric() * 1024,
    str_detect(size, &quot;MB$&quot;) ~ str_replace(size, &quot;MB$&quot;, &quot;&quot;) %&gt;% as.numeric() * 1024^2,
    str_detect(size, &quot;GB$&quot;) ~ str_replace(size, &quot;GB$&quot;, &quot;&quot;) %&gt;% as.numeric() * 1024^3,
    str_detect(size, &quot;B$&quot;) ~ str_replace(size, &quot;B$&quot;, &quot;&quot;) %&gt;% as.numeric(),
    TRUE ~ NA_real_
  )) %&gt;% 
  mutate(last_updated = -difftime(ymd_hms(lastUpdated), 
                                 ymd(&quot;2023-04-27&quot;), 
                                 units=&quot;days&quot;) %&gt;% as.numeric()) %&gt;% 
  rename(download_count = downloadCount,
         vote_count = voteCount,
         usability_rating = usabilityRating) %&gt;% 
  select(title, size, last_updated, download_count, vote_count, usability_rating)

head(kaggle_cleaned)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["title"],"name":[1],"type":["chr"],"align":["left"]},{"label":["size"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["last_updated"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["download_count"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["vote_count"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["usability_rating"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"animal crossing new horizons catalog","2":"590848","3":"687.3714","4":"39567","5":"31287","6":"0.8235294"},{"1":"covid19 open research dataset challenge cord19","2":"19327352832","3":"324.1808","4":"159879","5":"10400","6":"0.8823530"},{"1":"credit card fraud detection","2":"69206016","3":"1860.9462","4":"522136","5":"10088","6":"0.8529412"},{"1":"netflix movies and tv shows","2":"1048576","3":"576.8024","4":"332285","5":"7452","6":"1.0000000"},{"1":"novel corona virus 2019 dataset","2":"9437184","3":"671.8143","4":"404054","5":"5977","6":"0.9705882"},{"1":"chest xray images pneumonia","2":"2147483648","3":"1859.1792","4":"220969","5":"5651","6":"0.7500000"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>True to my pythonic ways, I snuck in changing all the multi-word
column names to snake case. The data looks much cleaner for some
exploratory analysis. Analyses can be visual, statistical, or both. For
the titles, I am going to use a word cloud to identify any especially
common words in our data.</p>
<pre class="r"><code>library(tidytext) # tokenize (split up) strings for us
library(wordcloud) # create word clouds

title_words = kaggle_cleaned %&gt;% 
  unnest_tokens(word, title)

title_word_freq = title_words %&gt;% count(word, sort = TRUE)

wordcloud(words = title_word_freq$word,
          freq = title_word_freq$n,
          scale = c(5, 0.5),
          min.freq = 1,
          max.words = 100,
          random.order = FALSE,
          rot.per = 0.3,
          colors = brewer.pal(10, &quot;Dark2&quot;))</code></pre>
<p><img src="final_project_tutorial_files/figure-html/it0_title_wordcloud-1.png" width="624" /></p>
<p>This is pretty cool except that the most common words are “dataset”
and “data” along with <a
href="https://en.wikipedia.org/wiki/Stop_word">stop words</a> like “the”
which are not super useful for our brainstorming. Let’s remove the stop
words and the words “data” and “dataset” explicitly from our analysis
and try again.</p>
<pre class="r"><code>title_words = kaggle_cleaned %&gt;%
  mutate(title = str_remove_all(title, &quot;\\bdata\\b&quot;)) %&gt;% 
  mutate(title = str_remove_all(title, &quot;\\bdataset\\b&quot;)) %&gt;% 
  unnest_tokens(word, title) %&gt;% 
  anti_join(stop_words)

title_word_freq = title_words %&gt;% count(word, sort = TRUE)

wordcloud(words = title_word_freq$word,
          freq = title_word_freq$n,
          scale = c(2, 0.25),
          min.freq = 1,
          max.words = 100,
          random.order = FALSE,
          rot.per = 0.3,
          colors = brewer.pal(10, &quot;Dark2&quot;))</code></pre>
<p><img src="final_project_tutorial_files/figure-html/it0_rm_stopwords-1.png" width="624" /></p>
<p>Now we are talking! The saturation of Covid analyses abides. I hope
it is different for you dear reader of the future. We also see
“classification”, “detection”, and “prediction” rank pretty highly
suggesting that a lot of these datasets were created with a specific
kind of analysis in mind.</p>
<p>Let’s do some standard statistical analyses on our numeric
columns.</p>
<pre class="r"><code>library(skimr) # Tidy summary stats
kaggle_cleaned %&gt;% 
  select_if(is.numeric) %&gt;% 
  skim()</code></pre>
<table>
<caption>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">Piped data</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">9991</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">5</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">5</td>
</tr>
<tr class="odd">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<colgroup>
<col width="13%" />
<col width="8%" />
<col width="11%" />
<col width="10%" />
<col width="10%" />
<col width="4%" />
<col width="7%" />
<col width="8%" />
<col width="9%" />
<col width="10%" />
<col width="4%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">size</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">755158581.39</td>
<td align="right">5.600048e+09</td>
<td align="right">0.00</td>
<td align="right">44544.00</td>
<td align="right">1048576.00</td>
<td align="right">51380224.00</td>
<td align="right">3.972845e+11</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">last_updated</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">879.43</td>
<td align="right">6.668000e+02</td>
<td align="right">-0.91</td>
<td align="right">291.28</td>
<td align="right">757.45</td>
<td align="right">1325.88</td>
<td align="right">2.543370e+03</td>
<td align="left">▇▅▃▂▂</td>
</tr>
<tr class="odd">
<td align="left">download_count</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4742.69</td>
<td align="right">1.725977e+04</td>
<td align="right">0.00</td>
<td align="right">558.00</td>
<td align="right">1288.00</td>
<td align="right">3192.50</td>
<td align="right">5.221360e+05</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">vote_count</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">100.25</td>
<td align="right">4.357600e+02</td>
<td align="right">21.00</td>
<td align="right">29.00</td>
<td align="right">39.00</td>
<td align="right">67.00</td>
<td align="right">3.128700e+04</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">usability_rating</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.82</td>
<td align="right">2.100000e-01</td>
<td align="right">0.00</td>
<td align="right">0.74</td>
<td align="right">0.88</td>
<td align="right">1.00</td>
<td align="right">1.000000e+00</td>
<td align="left">▁▁▁▂▇</td>
</tr>
</tbody>
</table>
<p><code>skimr</code> is so nice. Make sure to highlight your way over
if you don’t see a slider bar to see the little histogram it generates.
We have no missing values, but there is some clear evidence of skewing
in all of our columns. Let’s make some histograms to see that more
explicitly.</p>
<pre class="r"><code>library(ggplot2)
ggplot(kaggle_cleaned, aes(size)) + geom_histogram()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/it0_histogram_-1.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(last_updated)) + geom_histogram()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/it0_histogram_-2.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(download_count)) + geom_histogram()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/it0_histogram_-3.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(vote_count)) + geom_histogram()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/it0_histogram_-4.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(usability_rating)) + geom_histogram()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/it0_histogram_-5.png" width="624" /></p>
<p>We can confirm the significant skew we saw in the <code>skimr</code>
output with all but <code>usability_rating</code> having right skews and
<code>usability_rating</code> having a left skew. We will need to keep
that in mind when we start modeling as we will likely have to transform
the data to fit a GLM model.</p>
<p>This takes us to the important step of what we want to hypothesize as
an answer to our question. Keeping in mind our broad goal, “What data do
people create datasets on Kaggle to analyze?” We might consider naively,
for the sake of our overarching pedagogical goals, that the columns need
no further preprocessing. We will just fit the full model taking
<code>votes</code> as the response. Our hypothesis would be, “A dataset
which people want to analyze on Kaggle will have a high number of
upvotes and we can predict those upvotes using the other data provided
with the API responses listing datasets.”</p>
</div>
<div id="section-naive-bayes-modeling.-hold-the-bayes."
class="section level3">
<h3>Naive Bayes Modeling. Hold The Bayes.</h3>
<p>We have made our decisions and chosen our model, sort of. We know it
needs to be a Generalized Linear Model, and I assume that by the end of
this course you are aware that GLMs require a linking function depending
on the model design. In our case, we have a categorical predictor
<code>title</code> and four numerical predictors. If we want to model
<code>vote_count</code> as the response, we could use gamma regression
which is used for modeling positive, continuous responses with heavy
right skew. Our <code>vote_count</code> model checks all the boxes
<em>except</em> it is skewed to the left. We could try to finesse it a
bit, but the better model to use while still being a little naive is the
negative-binomial distribution regression. We can use
<code>tidymodels</code> to make the setup of our train and test split
and cross validation more straight forward.</p>
<pre class="r"><code>library(tidymodels) # Simplify model design specifications
library(parsnip)
library(MASS)
set.seed(42723) # Ensure you see the same &quot;random&quot; results I do
split_idx = initial_split(kaggle_cleaned)

# Test / Train split
kaggle_train = training(split_idx)
kaggle_test = testing(split_idx)

# Get an estimate of theta

estimate_theta_mod = glm.nb(vote_count ~ ., data=kaggle_train, maxit=10)

# Define the recipe
nb_recipe =  recipe(vote_count ~ ., data = kaggle_train) %&gt;% 
  step_dummy(all_nominal_predictors()) %&gt;% 
  step_zv(all_predictors()) %&gt;% 
  step_scale(all_predictors()) %&gt;% 
  step_center(all_predictors())

# Define the model specification
nb_spec =  linear_reg() %&gt;% 
  set_engine(&quot;glm&quot;, family = negative.binomial(estimated_theta_mod$theta), control = list(maxit = 10)) %&gt;% 
  set_mode(&quot;regression&quot;)

# Combine the recipe and model specification into a workflow
nb_wf =  workflow() %&gt;% 
  add_recipe(nb_recipe) %&gt;% 
  add_model(nb_spec)

# Fit the model using cross-validation
cv_results =  nb_wf %&gt;% 
  fit_resamples(
    resamples = vfold_cv(kaggle_train, v = 5),
    metrics = metric_set(rmse, rsq),
    control = control_resamples(save_pred = TRUE)
  )

# Extract the best model and re-fit it on the full training set
best_model = select_best(cv_results, &quot;rmse&quot;)
final_fit = best_model$workflow %&gt;% fit(data = kaggle_train)

# Use the model to predict on the test data
pred = final_fit %&gt;% predict(kaggle_test)

# Evaluate the model&#39;s performance
metrics(pred, truth = kaggle_test$vote_count)</code></pre>
<p>This model is not going to work. My computer is fighting for its
life. With only 10 iterations of <code>glm.nb</code> towards an estimate
of the dispersion parameter, it is unlikely that it was a great
estimate. Even with only ten iterations I could not execute. This is
largely do to our mishandling of our categorical variable and a bit to
do with the overdispersion in our numerical data.It’s also because of
the size of our dataset and the Maximum Likelihood Estimation being used
to optimize the dispersion parameter. We can do better with some more
well thought out preprocessing. Let’s do another iteration with
feeling!</p>
</div>
</div>
<div id="section-reflection-on-iteration-0" class="section level2">
<h2>Reflection On Iteration 0</h2>
<p>Yes, I do think I have a good grasp on the following:</p>
<ul>
<li>Describe probability as a foundation of statistical modeling,
including inference and maximum likelihood estimation</li>
<li>Determine and apply the appropriate generalized linear model for a
specific data context</li>
<li>Conduct model selection for a set of candidate models</li>
<li>Communicate the results of statistical models to a general
audience</li>
<li>Use programming software (i.e., R) to fit and assess statistical
models</li>
</ul>
<p>The first iteration alone showed my grasp of probability as a
foundation of statistical modeling. Why cross-validate? Why give up on
trying to make <code>glm.nb</code> work? I understand that MLE required
to regress an optimal value of the dispersion parameter is a series of
matrix multiplication which even in the best case is bounded by
dimensions of our model design matrix. With a categorical variable that
consists of around 10,000 unique values that will lead inevitably to a
slow, cumbersome calculation which makes any normal computer sound like
a boxfan.</p>
<p>The negative binomial regression is appropriate for right skewed data
which is overdispersed but does not have an excess of zero values. It is
just tough to fit without some additional adjustments.</p>
<p>The cross validation method is one way to conduct model selection by
training on different resamplings of a train split and choosing optimal
coefficients. There are further ways to conduct hyperparameter tuning
which is not happening with our current design matrix.</p>
<p>I like to think that while I have not provided results yet this model
was interesting to see and I am communicating in a way that is effective
even for a general audience. The results of the exploratory analysis
having visual components is important to have an audience actually pay
attention.</p>
<p>I definitely need to have a model that works for the final bullet but
we are getting there.</p>
</div>
<div id="section-example-project-iteration-1" class="section level2">
<h2>Example Project: Iteration 1</h2>
<p>Let’s set some goals here. We need to simplify our categorical
variable–a lot. We need to consider ways to also simplify our numerical
variables. If we can, an ideal plan of action would be a model which
also has more chance of running with more intensive model selection
methods. We will begin with some further exploratory analysis and
cleaning</p>
<div id="section-exploring-calmer-waters" class="section level3">
<h3>Exploring Calmer Waters</h3>
<p>Let’s start with the beefier of the two problems. How do we wrangle
our categorical variable into something actually usable? We need to (not
being facetious) categorize it. Meaning that we need to find some way to
process the records and assign them to one of <code>n</code> categories
where <code>n</code> is significantly smaller than 10,000. I think
ideally less than ten. To do this, I am going to flex some NLP muscle a
bit. The other option would be to use some simpler text processing and
similarity methods, but why do that when I could ask my friend BERT?</p>
<pre class="r"><code># Retrieved in part from https://www.kaggle.com/code/pehahn/basic-bert-with-r/script
reticulate::py_install(&#39;transformers&#39;, pip = TRUE)
transformer = reticulate::import(&#39;transformers&#39;)
tf = reticulate::import(&#39;tensorflow&#39;)
builtins = reticulate::import_builtins() #built in python methods
tokenizer = transformer$AutoTokenizer$from_pretrained(&#39;cardiffnlp/tweet-topic-21-multi&#39;)
model = transformer$TFAutoModelForSequenceClassification$from_pretrained(&#39;cardiffnlp/tweet-topic-21-multi&#39;)
class_mapping = model$config$id2label
text = kaggle_cleaned$title
tokens = tokenizer(text, truncation=TRUE, padding=TRUE,max_length=250L, return_tensors=&quot;tf&quot;)
results = model(tokens)

numpy = reticulate::import(&quot;numpy&quot;) # More python
scipy.special = reticulate::import(&quot;scipy.special&quot;) # More python

scores = numpy$array(results$logits) # Create an array from tensorflow object
write_csv(scores, &quot;scores.csv&quot;) # Write to a csv to prevent needing to rerun model</code></pre>
<pre class="r"><code>reticulate::py_install(&#39;scipy&#39;, pip = TRUE) # Setup some python utilities
numpy = reticulate::import(&quot;numpy&quot;) # More python
scipy.special = reticulate::import(&quot;scipy.special&quot;) # More python

class_mapping = c(&quot;arts_&amp;_culture&quot;,&quot;business_&amp;_entrepreneurs&quot;,&quot;celebrity_&amp;_pop_culture&quot;,
                  &quot;diaries_&amp;_daily_life&quot;,&quot;family&quot;,&quot;fashion_&amp;_style&quot;,&quot;film_tv_&amp;_video&quot;,
                  &quot;fitness_&amp;_health&quot;,&quot;food_&amp;_dining&quot;,&quot;gaming&quot;,&quot;learning_&amp;_educational&quot;,
                  &quot;music&quot;,&quot;news_&amp;_social_concern&quot;,&quot;other_hobbies&quot;,&quot;relationships&quot;,
                  &quot;science_&amp;_technology&quot;,&quot;sports&quot;,&quot;travel_&amp;_adventure&quot;,&quot;youth_&amp;_student_life&quot;)
scores = as.data.frame(read_csv(&quot;scores.csv&quot;, col_types=&quot;dd&quot;))
expit_scores = 1/(1 + exp(-scores)) # Convert scores to probabilities via expit function
score_predictions = as.data.frame(expit_scores &gt;= 0.5) # Use a threshold of 0.5 confidence to assign class

select_class = function(mask, classes) {
  ifelse(sum(unlist(mask))&gt;0, unlist(classes[mask][1]), &quot;No Class&quot;)
}
pred_classes = unlist(apply(score_predictions, 1, select_class, classes=class_mapping))
kaggle_cleaned$title_class = pred_classes
head(kaggle_cleaned)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["title"],"name":[1],"type":["chr"],"align":["left"]},{"label":["size"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["last_updated"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["download_count"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["vote_count"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["usability_rating"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["title_class"],"name":[7],"type":["chr"],"align":["left"]}],"data":[{"1":"animal crossing new horizons catalog","2":"590848","3":"687.3714","4":"39567","5":"31287","6":"0.8235294","7":"gaming"},{"1":"covid19 open research dataset challenge cord19","2":"19327352832","3":"324.1808","4":"159879","5":"10400","6":"0.8823530","7":"fitness_&_health"},{"1":"credit card fraud detection","2":"69206016","3":"1860.9462","4":"522136","5":"10088","6":"0.8529412","7":"business_&_entrepreneurs"},{"1":"netflix movies and tv shows","2":"1048576","3":"576.8024","4":"332285","5":"7452","6":"1.0000000","7":"film_tv_&_video"},{"1":"novel corona virus 2019 dataset","2":"9437184","3":"671.8143","4":"404054","5":"5977","6":"0.9705882","7":"fitness_&_health"},{"1":"chest xray images pneumonia","2":"2147483648","3":"1859.1792","4":"220969","5":"5651","6":"0.7500000","7":"fitness_&_health"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Whoa! What just happened and who is BERT? BERT is a bidirectional
encoder representation from transformers. It is an incredible natural
language processing model and we used a <a
href="https://huggingface.co/cardiffnlp/tweet-topic-21-multi">pretrained
model from HuggingFace’s community.</a> It was originally trained to
classify the topic of tweets with a corpus of over 11000 tweets used to
tune another model, TimeLMs, which was trained on over 124 million
tweets. All that going on and it still was able to run when
<code>glm.nb</code> would not! That’s because throughout I used
<code>reticulate</code> to make calls to some deep learning and numerics
libraries which were able to nearly blow up my computer by maxing out
CPU utilization. It was scary to watch. The result is not flawless
though. Let’s explore our transformed data some more to see what else we
might need to do.</p>
<pre class="r"><code>title_class_bars = kaggle_cleaned %&gt;% 
  select(title_class) %&gt;% 
  group_by(title_class) %&gt;% 
  count() %&gt;% 
  mutate(class_count = n) %&gt;% 
  select(title_class, class_count) %&gt;% 
  arrange(desc(class_count))

ggplot(data=title_class_bars, aes(x=reorder(title_class,class_count), 
                                  y=class_count, fill=title_class)) + 
  geom_bar(stat=&quot;identity&quot;) +
  xlab(&quot;title_class&quot;) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.key.height = unit(0.45,&#39;cm&#39;),
        legend.text = element_text(size=8))+
  scale_fill_discrete(breaks=levels(with(title_class_bars,
                                         reorder(title_class, class_count))))</code></pre>
<p><img src="final_project_tutorial_files/figure-html/it1_your_bert_is_a_wonderland-1.png" width="624" /></p>
<p>With this chart, it’s clear that a good portion of the data did not
get classified. With almost 2000 of our under 10000 records, we have to
decide how to handle this missing data. For now, I think we can again
drop it (naively). Let’s try to clean up our numerical data. We have a
lot of numerical data where the specific value doesn’t really matter as
much as its rough grouping. Is it very usable data? Is it a low number
of votes? We can create ordinal categorical variables to simplify some
of our modeling. Looking back at our project goal, we might think that
the main point of using <code>vote_count</code> is to measure
popularity. Why not split <code>vote_count</code> up into popular and
unpopular categories like the social hierarchy of a high school in a
coming of age film.</p>
<pre class="r"><code>library(janitor)
ggplot(kaggle_cleaned, aes(vote_count)) + geom_histogram()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/it1_hot_or_not-1.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(log(vote_count))) + geom_histogram()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/it1_hot_or_not-2.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(log(log(vote_count)))) + geom_histogram()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/it1_hot_or_not-3.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(sqrt(vote_count))) + geom_histogram()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/it1_hot_or_not-4.png" width="624" /></p>
<pre class="r"><code>MASS::boxcox(kaggle_cleaned$vote_count ~ 1)
lambda_loglik = MASS::boxcox(kaggle_cleaned$vote_count ~ 1)</code></pre>
<p><img src="final_project_tutorial_files/figure-html/it1_hot_or_not-5.png" width="624" /></p>
<pre class="r"><code>lambda = lambda_loglik$x[which.max(lambda_loglik$y)]
ggplot(kaggle_cleaned, aes((vote_count^lambda - 1)/lambda)) + geom_histogram(bins=30) + 
  xlab(&quot;BOXCOX(vote_count, lambda = -1/90)&quot;)</code></pre>
<p><img src="final_project_tutorial_files/figure-html/it1_hot_or_not-6.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(qnorm((ifelse(rank(vote_count)/length(vote_count) == 1,
                                        (rank(vote_count) - 1)/length(vote_count),
                                         rank(vote_count)/length(vote_count))))))+ 
  geom_histogram() +
  xlab(&quot;Quantile Transformation(vote_count)&quot;)</code></pre>
<p><img src="final_project_tutorial_files/figure-html/it1_hot_or_not-7.png" width="624" /></p>
<pre class="r"><code>kaggle_cleaned$vote_count_std = qnorm((ifelse(
  rank(kaggle_cleaned$vote_count)/length(kaggle_cleaned$vote_count) == 1,
  (rank(kaggle_cleaned$vote_count) - 1)/length(kaggle_cleaned$vote_count),
  rank(kaggle_cleaned$vote_count)/length(kaggle_cleaned$vote_count))))
kaggle_cleaned = kaggle_cleaned %&gt;% 
  mutate(popularity = ifelse(vote_count_std &gt; mean(vote_count_std),
                             &quot;Popular&quot;,
                             &quot;Not Popular&quot;)) %&gt;% 
  select(-vote_count_std)

kaggle_cleaned %&gt;% 
  tabyl(title_class, popularity) %&gt;% 
  adorn_percentages(&quot;row&quot;) %&gt;%
  adorn_pct_formatting(digits = 2) %&gt;%
  adorn_ns()</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["title_class"],"name":[1],"type":["chr"],"align":["left"]},{"label":["Not Popular"],"name":[2],"type":["chr"],"align":["left"]},{"label":["Popular"],"name":[3],"type":["chr"],"align":["left"]}],"data":[{"1":"arts_&_culture","2":"51.41%  (73)","3":"48.59%    (69)","_rn_":"1"},{"1":"business_&_entrepreneurs","2":"49.97% (758)","3":"50.03%   (759)","_rn_":"2"},{"1":"celebrity_&_pop_culture","2":"51.67%  (62)","3":"48.33%    (58)","_rn_":"3"},{"1":"diaries_&_daily_life","2":"47.33% (115)","3":"52.67%   (128)","_rn_":"4"},{"1":"family","2":"25.00%   (1)","3":"75.00%     (3)","_rn_":"5"},{"1":"fashion_&_style","2":"60.56%  (43)","3":"39.44%    (28)","_rn_":"6"},{"1":"film_tv_&_video","2":"52.18% (299)","3":"47.82%   (274)","_rn_":"7"},{"1":"fitness_&_health","2":"48.31% (414)","3":"51.69%   (443)","_rn_":"8"},{"1":"food_&_dining","2":"42.75% (112)","3":"57.25%   (150)","_rn_":"9"},{"1":"gaming","2":"47.96% (129)","3":"52.04%   (140)","_rn_":"10"},{"1":"learning_&_educational","2":"48.52% (213)","3":"51.48%   (226)","_rn_":"11"},{"1":"music","2":"46.00%  (92)","3":"54.00%   (108)","_rn_":"12"},{"1":"news_&_social_concern","2":"50.71% (861)","3":"49.29%   (837)","_rn_":"13"},{"1":"No Class","2":"49.26% (971)","3":"50.74% (1,000)","_rn_":"14"},{"1":"other_hobbies","2":"44.44%  (12)","3":"55.56%    (15)","_rn_":"15"},{"1":"relationships","2":"0.00%   (0)","3":"100.00%     (2)","_rn_":"16"},{"1":"science_&_technology","2":"51.66% (450)","3":"48.34%   (421)","_rn_":"17"},{"1":"sports","2":"52.03% (282)","3":"47.97%   (260)","_rn_":"18"},{"1":"travel_&_adventure","2":"55.74% (102)","3":"44.26%    (81)","_rn_":"19"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>We tried some different ways to remove the skew from our data but
eventually we just coerced it to a normal distribution to split it
apart. The resulting <code>popularity</code> column can be seen in the
cross-table to be pretty evenly split across all title classes other
than where we have sparse data. Let’s suppose again that we can naively
fit a model of <code>popularity</code> as we have built it. What would
our hypothesis be?</p>
<p>I would hypothesize that people creating Kaggle datasets that are
larger, more usable, and that the topic plays an important role in
determining popularity. I think the recency of an update is less
important and I think that downloads may be explored as a possible
second response variable.</p>
</div>
<div id="section-modeling-coin-tosses-but-make-it-cool"
class="section level3">
<h3>Modeling Coin Tosses But Make It Cool</h3>
<p>We have walked our way into a logistic regression which should be
interesting to conduct. We have a binary response, one nominal
predictor, and two numerical predictors we want to use. Let’s put
together a model workflow and see what we can see!</p>
<pre class="r"><code>library(tidymodels)
# Pulling from https://www.tidymodels.org/start/case-study/
set.seed(42723)
splits      = initial_split(kaggle_cleaned)

kaggle_other = training(splits)
kaggle_test  = testing(splits)

val_set = validation_split(kaggle_other, 
                            prop = 0.80)

lr_mod = logistic_reg(penalty = tune(), mixture = 1) %&gt;% 
  set_engine(&quot;glmnet&quot;)

lr_recipe = recipe(popularity ~ title_class + size + usability_rating, data = kaggle_other) %&gt;% 
  step_dummy(all_nominal_predictors()) %&gt;% 
  step_zv(all_predictors()) %&gt;% 
  step_normalize(all_predictors())

lr_workflow =  workflow() %&gt;% 
  add_model(lr_mod) %&gt;% 
  add_recipe(lr_recipe)

lr_reg_grid = tibble(penalty = 10^seq(-4, -1, length.out = 30))

lr_reg_grid %&gt;% top_n(-5)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["penalty"],"name":[1],"type":["dbl"],"align":["right"]}],"data":[{"1":"0.0001000000"},{"1":"0.0001268961"},{"1":"0.0001610262"},{"1":"0.0002043360"},{"1":"0.0002592944"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>lr_reg_grid %&gt;% top_n(5)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["penalty"],"name":[1],"type":["dbl"],"align":["right"]}],"data":[{"1":"0.03856620"},{"1":"0.04893901"},{"1":"0.06210169"},{"1":"0.07880463"},{"1":"0.10000000"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>lr_res = lr_workflow %&gt;% 
  tune_grid(val_set,
            grid = lr_reg_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))
lr_plot =
  lr_res %&gt;% 
  collect_metrics() %&gt;% 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  ylab(&quot;Area under the ROC Curve&quot;) +
  scale_x_log10(labels = scales::label_number())

lr_plot</code></pre>
<p><img src="final_project_tutorial_files/figure-html/big_ol_log-1.png" width="624" /></p>
<pre class="r"><code>top_models &lt;-
  lr_res %&gt;% 
  show_best(&quot;roc_auc&quot;, n = 15) %&gt;% 
  arrange(penalty) 
top_models</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["penalty"],"name":[1],"type":["dbl"],"align":["right"]},{"label":[".metric"],"name":[2],"type":["chr"],"align":["left"]},{"label":[".estimator"],"name":[3],"type":["chr"],"align":["left"]},{"label":["mean"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["n"],"name":[5],"type":["int"],"align":["right"]},{"label":["std_err"],"name":[6],"type":["dbl"],"align":["right"]},{"label":[".config"],"name":[7],"type":["chr"],"align":["left"]}],"data":[{"1":"0.0001000000","2":"roc_auc","3":"binary","4":"0.5263777","5":"1","6":"NA","7":"Preprocessor1_Model01"},{"1":"0.0001268961","2":"roc_auc","3":"binary","4":"0.5263777","5":"1","6":"NA","7":"Preprocessor1_Model02"},{"1":"0.0001610262","2":"roc_auc","3":"binary","4":"0.5263777","5":"1","6":"NA","7":"Preprocessor1_Model03"},{"1":"0.0002043360","2":"roc_auc","3":"binary","4":"0.5263777","5":"1","6":"NA","7":"Preprocessor1_Model04"},{"1":"0.0002592944","2":"roc_auc","3":"binary","4":"0.5263777","5":"1","6":"NA","7":"Preprocessor1_Model05"},{"1":"0.0003290345","2":"roc_auc","3":"binary","4":"0.5263777","5":"1","6":"NA","7":"Preprocessor1_Model06"},{"1":"0.0004175319","2":"roc_auc","3":"binary","4":"0.5263777","5":"1","6":"NA","7":"Preprocessor1_Model07"},{"1":"0.0013738238","2":"roc_auc","3":"binary","4":"0.5267586","5":"1","6":"NA","7":"Preprocessor1_Model12"},{"1":"0.0017433288","2":"roc_auc","3":"binary","4":"0.5269509","5":"1","6":"NA","7":"Preprocessor1_Model13"},{"1":"0.0022122163","2":"roc_auc","3":"binary","4":"0.5266839","5":"1","6":"NA","7":"Preprocessor1_Model14"},{"1":"0.0028072162","2":"roc_auc","3":"binary","4":"0.5308699","5":"1","6":"NA","7":"Preprocessor1_Model15"},{"1":"0.0035622479","2":"roc_auc","3":"binary","4":"0.5309883","5":"1","6":"NA","7":"Preprocessor1_Model16"},{"1":"0.0045203537","2":"roc_auc","3":"binary","4":"0.5319238","5":"1","6":"NA","7":"Preprocessor1_Model17"},{"1":"0.0057361525","2":"roc_auc","3":"binary","4":"0.5278668","5":"1","6":"NA","7":"Preprocessor1_Model18"},{"1":"0.0072789538","2":"roc_auc","3":"binary","4":"0.5263795","5":"1","6":"NA","7":"Preprocessor1_Model19"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>lr_best =
  lr_res %&gt;% 
  collect_metrics() %&gt;% 
  arrange(penalty) %&gt;% 
  slice(15)
lr_best</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["penalty"],"name":[1],"type":["dbl"],"align":["right"]},{"label":[".metric"],"name":[2],"type":["chr"],"align":["left"]},{"label":[".estimator"],"name":[3],"type":["chr"],"align":["left"]},{"label":["mean"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["n"],"name":[5],"type":["int"],"align":["right"]},{"label":["std_err"],"name":[6],"type":["dbl"],"align":["right"]},{"label":[".config"],"name":[7],"type":["chr"],"align":["left"]}],"data":[{"1":"0.002807216","2":"roc_auc","3":"binary","4":"0.5308699","5":"1","6":"NA","7":"Preprocessor1_Model15"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>lr_auc = lr_res %&gt;% 
  collect_predictions(parameters = lr_best) %&gt;% 
  roc_curve(popularity, .pred_Popular) %&gt;% 
  mutate(model = &quot;Logistic Regression&quot;)

autoplot(lr_auc)</code></pre>
<p><img src="final_project_tutorial_files/figure-html/big_ol_log-2.png" width="624" /></p>
<p>This is an incredibly bad result. It suggests that our data has no
power to predict the popularity of a dataset from the title classes,
usability ratings, and size of the data. This can be seen by how closely
our model follows the “no-skill” line which reflects the cut off for a
model to perform better than guessing at random. We are on to something
though with our response and categorical vectors being more manageable.
Now the question is finding the right model which calls for some further
exploration in a final iteration.</p>
</div>
</div>
<div id="section-reflecting-on-iteration-1" class="section level2">
<h2>Reflecting On Iteration 1</h2>
<p>I was able to better show my understanding of GLMs and some powerful
model fitting techniques in <code>tidymodels</code>. The weakest point
(intentionally) so far has been my exploratory analysis. With it being
loosely put together, I am running into data quality issues that are
inhibiting an otherwise interesting model. I think the NLP application
is fun, but it is more of a narrative device to show that bigger hammers
won’t help you screw something in. I think that this is the broader
message of the course objectives. A statistician should know what tool
to use in which situation with some expected effect. I think we can
squeeze something more useful out of this model in a final iteration
through proper preprocessing.</p>
</div>
<div id="section-example-project-iteration-2" class="section level2">
<h2>Example Project Iteration 2</h2>
<div
id="section-i-came-here-to-clean-data-and-chew-gum-and-i-am-all-out-of-gum"
class="section level3">
<h3>I Came Here To Clean Data And Chew Gum And I Am All Out Of Gum</h3>
<p>Hello <code>summary</code> my old friend.</p>
<pre class="r"><code>summary(kaggle_cleaned$size)</code></pre>
<pre><code>##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
## 0.000e+00 4.454e+04 1.049e+06 7.552e+08 5.138e+07 3.973e+11</code></pre>
<p>This is a great example of a simple tool and common sense can improve
models. What would it mean for a dataset with a zero byte size file to
be popular? I don’t know but in our model it is going to mean
nothing.</p>
<pre class="r"><code>kaggle_cleaned = kaggle_cleaned %&gt;% filter(size != 0)
summary(kaggle_cleaned$size)</code></pre>
<pre><code>##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
## 2.200e+01 4.710e+04 1.049e+06 7.601e+08 5.243e+07 3.973e+11</code></pre>
<p>The zeros are gone and investigating some of the other small values
like 4906 reveals small but relevant zipped datasets. The next common
check is the distribution of the data. We have already looked at it, but
let’s look again along with some typical transformations of skewed data.
We will also investigate the outliers in the data using a boxplot.</p>
<pre class="r"><code>ggplot(data=kaggle_cleaned, aes(y=size)) + geom_boxplot()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/size_hists-1.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(size)) + geom_histogram()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/size_hists-2.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(log(size))) + geom_histogram()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/size_hists-3.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(log(log(size)))) + geom_histogram()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/size_hists-4.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(sqrt(size))) + geom_histogram()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/size_hists-5.png" width="624" /></p>
<pre class="r"><code>kaggle_cleaned$lgsize = log(kaggle_cleaned$size)
ggplot(data=kaggle_cleaned, aes(y=lgsize)) + geom_boxplot()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/size_hists-6.png" width="624" /></p>
<p>We can see that <code>log(size)</code> looks normally distributed and
when we use <code>lgsize</code> in a boxplot the data goes from being
nearly all outlier to there being no outliers. We can do a similar
analysis for <code>usability_rating</code> only we’ll want only
usability that is great than 0.5 or indicating it’s likely to be
usable.</p>
<pre class="r"><code>summary(kaggle_cleaned$usability_rating)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.0000  0.7353  0.8824  0.8234  1.0000  1.0000</code></pre>
<pre class="r"><code>kaggle_cleaned = kaggle_cleaned %&gt;% filter(usability_rating &gt; 0.5)
summary(kaggle_cleaned$usability_rating)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.5294  0.7941  0.9375  0.8788  1.0000  1.0000</code></pre>
<p>This has removed our zeros, but let’s look at some histograms to see
how the data is distributed.</p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(usability_rating)) + geom_histogram(bins=15)</code></pre>
<p><img src="final_project_tutorial_files/figure-html/usability_hists-1.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(log(usability_rating))) + geom_histogram(bins=15)</code></pre>
<p><img src="final_project_tutorial_files/figure-html/usability_hists-2.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(sqrt(usability_rating))) + geom_histogram(bins=15)</code></pre>
<p><img src="final_project_tutorial_files/figure-html/usability_hists-3.png" width="624" /></p>
<p>None of the transformations look right because the column has such
heavy skew to one. It is better to just break this up into near perfect
usability and not near perfect.</p>
<pre class="r"><code>kaggle_cleaned = kaggle_cleaned %&gt;% 
  mutate(usability = cut_number(usability_rating, n=2, labels=c(&quot;Usable&quot;, &quot;Highly Usable&quot;)))

kaggle_cleaned %&gt;% 
  tabyl(popularity, usability) %&gt;% 
  adorn_percentages(&quot;row&quot;) %&gt;%
  adorn_pct_formatting(digits = 2) %&gt;%  
  adorn_ns()</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["popularity"],"name":[1],"type":["chr"],"align":["left"]},{"label":["Usable"],"name":[2],"type":["chr"],"align":["left"]},{"label":["Highly Usable"],"name":[3],"type":["chr"],"align":["left"]}],"data":[{"1":"Not Popular","2":"48.37% (2,122)","3":"51.63% (2,265)","_rn_":"1"},{"1":"Popular","2":"53.32% (2,428)","3":"46.68% (2,126)","_rn_":"2"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>This change does not create an explicitly exploitable correlation
between the two variables but it seems that it may be able to help
contribute. Applying this same idea <code>last_updated</code>:</p>
<pre class="r"><code>summary(kaggle_cleaned$last_updated)</code></pre>
<pre><code>##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
##   -0.909  278.526  710.667  858.777 1260.223 2543.365</code></pre>
<pre class="r"><code>kaggle_cleaned = kaggle_cleaned %&gt;% 
  filter(last_updated &gt; 0)

summary(kaggle_cleaned$last_updated)</code></pre>
<pre><code>##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
##    0.0186  283.5100  716.7781  864.8736 1261.7186 2543.3651</code></pre>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(last_updated)) + geom_histogram(bins=15)</code></pre>
<p><img src="final_project_tutorial_files/figure-html/recency_is_a_weird_word-1.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(sqrt(last_updated))) + geom_histogram(bins=15)</code></pre>
<p><img src="final_project_tutorial_files/figure-html/recency_is_a_weird_word-2.png" width="624" /></p>
<pre class="r"><code>kaggle_cleaned$sqrtlast_updated = sqrt(kaggle_cleaned$last_updated)

ggplot(kaggle_cleaned, aes(y=sqrtlast_updated))+geom_boxplot()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/recency_is_a_weird_word-3.png" width="624" /></p>
<p>Again we have clean data and we are left with dealing with download
count which is highly correlated to our response of vote counts. We
investigate this relationship briefly before deciding to continue.</p>
<pre class="r"><code>summary(kaggle_cleaned$download_count)</code></pre>
<pre><code>##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
##      3.0    627.2   1341.0   4978.7   3273.0 522136.0</code></pre>
<pre class="r"><code>cor(kaggle_cleaned$download_count, kaggle_cleaned$vote_count)</code></pre>
<pre><code>## [1] 0.6233305</code></pre>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(download_count)) + geom_histogram(bins=30)</code></pre>
<p><img src="final_project_tutorial_files/figure-html/adding_downloads-1.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(log(download_count))) + geom_histogram(bins=30)</code></pre>
<p><img src="final_project_tutorial_files/figure-html/adding_downloads-2.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(log(log(download_count)))) + geom_histogram(bins=30)</code></pre>
<p><img src="final_project_tutorial_files/figure-html/adding_downloads-3.png" width="624" /></p>
<pre class="r"><code>ggplot(kaggle_cleaned, aes(sqrt(download_count))) + geom_histogram(bins=30)</code></pre>
<p><img src="final_project_tutorial_files/figure-html/adding_downloads-4.png" width="624" /></p>
<pre class="r"><code>kaggle_cleaned %&gt;% 
  filter(popularity == &quot;Not Popular&quot;) %&gt;% 
  filter(download_count &gt; mean(download_count)) %&gt;% 
  select(download_count) %&gt;% 
  count()</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["n"],"name":[1],"type":["int"],"align":["right"]}],"data":[{"1":"1686"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>kaggle_cleaned %&gt;% 
  filter(popularity == &quot;Popular&quot;) %&gt;% 
  filter(download_count &gt; mean(download_count)) %&gt;% 
  select(download_count) %&gt;% 
  count()</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["n"],"name":[1],"type":["int"],"align":["right"]}],"data":[{"1":"895"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>kaggle_cleaned %&gt;% 
  filter(popularity == &quot;Not Popular&quot;) %&gt;% 
  filter(download_count &lt; mean(download_count)) %&gt;% 
  select(download_count) %&gt;% 
  count()</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["n"],"name":[1],"type":["int"],"align":["right"]}],"data":[{"1":"2678"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>kaggle_cleaned %&gt;% 
  filter(popularity == &quot;Popular&quot;) %&gt;% 
  filter(download_count &lt; mean(download_count)) %&gt;% 
  select(download_count) %&gt;% 
  count()</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["n"],"name":[1],"type":["int"],"align":["right"]}],"data":[{"1":"3619"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>There’s no great way to split up the data via potential response
levels. Instead, we can use kmeans to engineer a feature which captures
a bit about all the columns for some subsection of the data.</p>
<pre class="r"><code>library(factoextra)
kaggle_kmeans_data = kaggle_cleaned %&gt;% 
  select(vote_count, usability_rating, last_updated, size, download_count) %&gt;% 
  mutate(across(everything(), scale))

kaggle_kmeans_data %&gt;% 
  skim()</code></pre>
<table>
<caption>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">Piped data</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">8878</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">5</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">5</td>
</tr>
<tr class="odd">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table style="width:100%;">
<colgroup>
<col width="20%" />
<col width="11%" />
<col width="16%" />
<col width="5%" />
<col width="3%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">vote_count</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">-0.18</td>
<td align="right">-0.17</td>
<td align="right">-0.14</td>
<td align="right">-0.08</td>
<td align="right">67.61</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">usability_rating</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">-2.67</td>
<td align="right">-0.65</td>
<td align="right">0.45</td>
<td align="right">0.93</td>
<td align="right">0.93</td>
<td align="left">▁▂▂▃▇</td>
</tr>
<tr class="odd">
<td align="left">last_updated</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">-1.29</td>
<td align="right">-0.87</td>
<td align="right">-0.22</td>
<td align="right">0.59</td>
<td align="right">2.50</td>
<td align="left">▇▅▃▂▂</td>
</tr>
<tr class="even">
<td align="left">size</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">-0.17</td>
<td align="right">-0.17</td>
<td align="right">-0.17</td>
<td align="right">-0.16</td>
<td align="right">24.07</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">download_count</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">-0.27</td>
<td align="right">-0.24</td>
<td align="right">-0.20</td>
<td align="right">-0.09</td>
<td align="right">28.51</td>
<td align="left">▇▁▁▁▁</td>
</tr>
</tbody>
</table>
<pre class="r"><code>elbow = fviz_nbclust(kaggle_kmeans_data, kmeans, method=&quot;wss&quot;)
elbow$data</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["clusters"],"name":[1],"type":["fct"],"align":["left"]},{"label":["y"],"name":[2],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"44385.00"},{"1":"2","2":"33572.99"},{"1":"3","2":"30686.34"},{"1":"4","2":"23635.74"},{"1":"5","2":"17508.54"},{"1":"6","2":"16026.23"},{"1":"7","2":"13416.11"},{"1":"8","2":"12521.70"},{"1":"9","2":"12186.29"},{"1":"10","2":"10462.14"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>ggplot(data=elbow$data, aes(x=clusters, y=y))+geom_point()</code></pre>
<p><img src="final_project_tutorial_files/figure-html/popular_but_fake-1.png" width="624" /></p>
<pre class="r"><code>kaggle_km_mod = kmeans(kaggle_kmeans_data, centers=5, nstart=25)
kaggle_clustered = kaggle_cleaned %&gt;% 
  mutate(cluster = as.factor(kaggle_km_mod$cluster),
         popularity = as.factor(popularity),
         usability = as.factor(usability),
         title_class = as.factor(title_class))</code></pre>
<p>This creates a nice cluster feature for us to use in our model as a
dummy variable which only effects the data when turned on. We can also
skim the clusters to see if there’s any interpretable way to describe
them.</p>
<pre class="r"><code>kaggle_clustered %&gt;% 
  group_by(cluster) %&gt;% 
  skim() %&gt;% 
  arrange(cluster)</code></pre>
<table>
<caption>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">Piped data</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">8878</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">12</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">factor</td>
<td align="left">3</td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">7</td>
</tr>
<tr class="odd">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Group variables</td>
<td align="left">cluster</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<colgroup>
<col width="17%" />
<col width="10%" />
<col width="12%" />
<col width="17%" />
<col width="5%" />
<col width="5%" />
<col width="7%" />
<col width="11%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="left">cluster</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">title</td>
<td align="left">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">6</td>
<td align="right">50</td>
<td align="right">0</td>
<td align="right">49</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">title</td>
<td align="left">2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">6</td>
<td align="right">50</td>
<td align="right">0</td>
<td align="right">1610</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">title</td>
<td align="left">3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5</td>
<td align="right">50</td>
<td align="right">0</td>
<td align="right">1979</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">title</td>
<td align="left">4</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">10</td>
<td align="right">49</td>
<td align="right">0</td>
<td align="right">58</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">title</td>
<td align="left">5</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">6</td>
<td align="right">50</td>
<td align="right">0</td>
<td align="right">5084</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<colgroup>
<col width="13%" />
<col width="7%" />
<col width="9%" />
<col width="13%" />
<col width="7%" />
<col width="8%" />
<col width="38%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="left">cluster</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">title_class</td>
<td align="left">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">11</td>
<td align="left">No : 13, sci: 7, bus: 6, fit: 5</td>
</tr>
<tr class="even">
<td align="left">popularity</td>
<td align="left">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Pop: 29, Not: 20</td>
</tr>
<tr class="odd">
<td align="left">usability</td>
<td align="left">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Usa: 37, Hig: 12</td>
</tr>
<tr class="even">
<td align="left">title_class</td>
<td align="left">2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">19</td>
<td align="left">No : 366, new: 257, bus: 198, fit: 180</td>
</tr>
<tr class="odd">
<td align="left">popularity</td>
<td align="left">2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Not: 966, Pop: 651</td>
</tr>
<tr class="even">
<td align="left">usability</td>
<td align="left">2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">1</td>
<td align="left">Usa: 1617, Hig: 0</td>
</tr>
<tr class="odd">
<td align="left">title_class</td>
<td align="left">3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">18</td>
<td align="left">No : 431, new: 406, bus: 257, sci: 167</td>
</tr>
<tr class="even">
<td align="left">popularity</td>
<td align="left">3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Pop: 1398, Not: 601</td>
</tr>
<tr class="odd">
<td align="left">usability</td>
<td align="left">3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Usa: 1933, Hig: 66</td>
</tr>
<tr class="even">
<td align="left">title_class</td>
<td align="left">4</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">13</td>
<td align="left">fit: 10, bus: 9, No : 9, new: 7</td>
</tr>
<tr class="odd">
<td align="left">popularity</td>
<td align="left">4</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">1</td>
<td align="left">Pop: 58, Not: 0</td>
</tr>
<tr class="even">
<td align="left">usability</td>
<td align="left">4</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Usa: 42, Hig: 16</td>
</tr>
<tr class="odd">
<td align="left">title_class</td>
<td align="left">5</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">18</td>
<td align="left">new: 918, bus: 894, No : 751, fit: 474</td>
</tr>
<tr class="even">
<td align="left">popularity</td>
<td align="left">5</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Not: 2777, Pop: 2378</td>
</tr>
<tr class="odd">
<td align="left">usability</td>
<td align="left">5</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Hig: 4253, Usa: 902</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table style="width:100%;">
<colgroup>
<col width="11%" />
<col width="5%" />
<col width="6%" />
<col width="9%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="4%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="left">cluster</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">size</td>
<td align="left">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4.106515e+10</td>
<td align="right">1.904004e+10</td>
<td align="right">2.147484e+10</td>
<td align="right">2.57698e+10</td>
<td align="right">3.435974e+10</td>
<td align="right">5.046587e+10</td>
<td align="right">9.126806e+10</td>
<td align="left">▇▃▂▂▁</td>
</tr>
<tr class="even">
<td align="left">last_updated</td>
<td align="left">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">7.821600e+02</td>
<td align="right">5.571900e+02</td>
<td align="right">2.110000e+00</td>
<td align="right">3.13860e+02</td>
<td align="right">7.289400e+02</td>
<td align="right">1.417730e+03</td>
<td align="right">1.890130e+03</td>
<td align="left">▇▅▆▃▃</td>
</tr>
<tr class="odd">
<td align="left">download_count</td>
<td align="left">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4.621450e+03</td>
<td align="right">1.039725e+04</td>
<td align="right">8.800000e+01</td>
<td align="right">5.12000e+02</td>
<td align="right">1.265000e+03</td>
<td align="right">5.989000e+03</td>
<td align="right">7.008700e+04</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">vote_count</td>
<td align="left">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.100800e+02</td>
<td align="right">1.703000e+02</td>
<td align="right">2.200000e+01</td>
<td align="right">3.00000e+01</td>
<td align="right">4.400000e+01</td>
<td align="right">1.170000e+02</td>
<td align="right">1.015000e+03</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">usability_rating</td>
<td align="left">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">8.200000e-01</td>
<td align="right">1.300000e-01</td>
<td align="right">5.600000e-01</td>
<td align="right">7.40000e-01</td>
<td align="right">8.200000e-01</td>
<td align="right">9.400000e-01</td>
<td align="right">1.000000e+00</td>
<td align="left">▅▃▇▇▇</td>
</tr>
<tr class="even">
<td align="left">lgsize</td>
<td align="left">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.435000e+01</td>
<td align="right">4.200000e-01</td>
<td align="right">2.379000e+01</td>
<td align="right">2.39700e+01</td>
<td align="right">2.426000e+01</td>
<td align="right">2.464000e+01</td>
<td align="right">2.524000e+01</td>
<td align="left">▇▅▃▃▂</td>
</tr>
<tr class="odd">
<td align="left">sqrtlast_updated</td>
<td align="left">1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.573000e+01</td>
<td align="right">1.107000e+01</td>
<td align="right">1.450000e+00</td>
<td align="right">1.77200e+01</td>
<td align="right">2.700000e+01</td>
<td align="right">3.765000e+01</td>
<td align="right">4.348000e+01</td>
<td align="left">▃▆▆▇▇</td>
</tr>
<tr class="even">
<td align="left">size</td>
<td align="left">2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.239402e+09</td>
<td align="right">3.291227e+09</td>
<td align="right">2.200000e+01</td>
<td align="right">1.42336e+05</td>
<td align="right">8.388608e+06</td>
<td align="right">4.131389e+08</td>
<td align="right">2.040109e+10</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">last_updated</td>
<td align="left">2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">7.053300e+02</td>
<td align="right">3.985100e+02</td>
<td align="right">2.000000e-02</td>
<td align="right">3.28440e+02</td>
<td align="right">7.362500e+02</td>
<td align="right">1.040330e+03</td>
<td align="right">1.780340e+03</td>
<td align="left">▇▆▇▆▁</td>
</tr>
<tr class="even">
<td align="left">download_count</td>
<td align="left">2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.919850e+03</td>
<td align="right">3.033710e+03</td>
<td align="right">3.000000e+00</td>
<td align="right">4.78000e+02</td>
<td align="right">1.003000e+03</td>
<td align="right">2.111000e+03</td>
<td align="right">5.598600e+04</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">vote_count</td>
<td align="left">2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4.974000e+01</td>
<td align="right">5.659000e+01</td>
<td align="right">2.100000e+01</td>
<td align="right">2.70000e+01</td>
<td align="right">3.400000e+01</td>
<td align="right">5.000000e+01</td>
<td align="right">1.158000e+03</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">usability_rating</td>
<td align="left">2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">7.300000e-01</td>
<td align="right">9.000000e-02</td>
<td align="right">5.300000e-01</td>
<td align="right">6.90000e-01</td>
<td align="right">7.500000e-01</td>
<td align="right">8.200000e-01</td>
<td align="right">9.400000e-01</td>
<td align="left">▃▃▇▇▁</td>
</tr>
<tr class="odd">
<td align="left">lgsize</td>
<td align="left">2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.580000e+01</td>
<td align="right">4.680000e+00</td>
<td align="right">3.090000e+00</td>
<td align="right">1.18700e+01</td>
<td align="right">1.594000e+01</td>
<td align="right">1.984000e+01</td>
<td align="right">2.374000e+01</td>
<td align="left">▁▆▇▇▇</td>
</tr>
<tr class="even">
<td align="left">sqrtlast_updated</td>
<td align="left">2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.507000e+01</td>
<td align="right">8.760000e+00</td>
<td align="right">1.400000e-01</td>
<td align="right">1.81200e+01</td>
<td align="right">2.713000e+01</td>
<td align="right">3.225000e+01</td>
<td align="right">4.219000e+01</td>
<td align="left">▁▃▅▇▃</td>
</tr>
<tr class="odd">
<td align="left">size</td>
<td align="left">3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3.641392e+08</td>
<td align="right">1.303377e+09</td>
<td align="right">2.620000e+02</td>
<td align="right">1.73568e+05</td>
<td align="right">4.194304e+06</td>
<td align="right">8.545894e+07</td>
<td align="right">1.610613e+10</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">last_updated</td>
<td align="left">3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.878680e+03</td>
<td align="right">3.021000e+02</td>
<td align="right">6.493300e+02</td>
<td align="right">1.65089e+03</td>
<td align="right">1.915950e+03</td>
<td align="right">2.088820e+03</td>
<td align="right">2.543370e+03</td>
<td align="left">▁▁▆▇▃</td>
</tr>
<tr class="odd">
<td align="left">download_count</td>
<td align="left">3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">8.397900e+03</td>
<td align="right">1.404620e+04</td>
<td align="right">6.000000e+01</td>
<td align="right">1.55750e+03</td>
<td align="right">3.258000e+03</td>
<td align="right">8.344500e+03</td>
<td align="right">1.152390e+05</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">vote_count</td>
<td align="left">3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.423900e+02</td>
<td align="right">2.291100e+02</td>
<td align="right">2.200000e+01</td>
<td align="right">3.50000e+01</td>
<td align="right">6.100000e+01</td>
<td align="right">1.365000e+02</td>
<td align="right">3.491000e+03</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">usability_rating</td>
<td align="left">3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">7.600000e-01</td>
<td align="right">1.000000e-01</td>
<td align="right">5.300000e-01</td>
<td align="right">7.10000e-01</td>
<td align="right">7.600000e-01</td>
<td align="right">8.200000e-01</td>
<td align="right">1.000000e+00</td>
<td align="left">▂▆▅▇▁</td>
</tr>
<tr class="even">
<td align="left">lgsize</td>
<td align="left">3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.515000e+01</td>
<td align="right">3.960000e+00</td>
<td align="right">5.570000e+00</td>
<td align="right">1.20600e+01</td>
<td align="right">1.525000e+01</td>
<td align="right">1.826000e+01</td>
<td align="right">2.350000e+01</td>
<td align="left">▂▆▇▇▃</td>
</tr>
<tr class="odd">
<td align="left">sqrtlast_updated</td>
<td align="left">3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4.320000e+01</td>
<td align="right">3.560000e+00</td>
<td align="right">2.548000e+01</td>
<td align="right">4.06300e+01</td>
<td align="right">4.377000e+01</td>
<td align="right">4.570000e+01</td>
<td align="right">5.043000e+01</td>
<td align="left">▁▁▃▇▆</td>
</tr>
<tr class="even">
<td align="left">size</td>
<td align="left">4</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5.060060e+08</td>
<td align="right">2.594779e+09</td>
<td align="right">2.048000e+03</td>
<td align="right">5.04320e+04</td>
<td align="right">1.048576e+06</td>
<td align="right">5.138022e+07</td>
<td align="right">1.932735e+10</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">last_updated</td>
<td align="left">4</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.544470e+03</td>
<td align="right">6.681700e+02</td>
<td align="right">3.241800e+02</td>
<td align="right">8.98130e+02</td>
<td align="right">1.748220e+03</td>
<td align="right">2.047530e+03</td>
<td align="right">2.435340e+03</td>
<td align="left">▆▃▃▇▇</td>
</tr>
<tr class="even">
<td align="left">download_count</td>
<td align="left">4</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.768638e+05</td>
<td align="right">9.772925e+04</td>
<td align="right">3.956700e+04</td>
<td align="right">1.12031e+05</td>
<td align="right">1.407550e+05</td>
<td align="right">2.105930e+05</td>
<td align="right">5.221360e+05</td>
<td align="left">▇▆▂▁▁</td>
</tr>
<tr class="odd">
<td align="left">vote_count</td>
<td align="left">4</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3.554450e+03</td>
<td align="right">4.148120e+03</td>
<td align="right">1.190000e+03</td>
<td align="right">1.96125e+03</td>
<td align="right">2.440500e+03</td>
<td align="right">3.542000e+03</td>
<td align="right">3.128700e+04</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">usability_rating</td>
<td align="left">4</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">8.600000e-01</td>
<td align="right">1.000000e-01</td>
<td align="right">5.900000e-01</td>
<td align="right">7.90000e-01</td>
<td align="right">8.600000e-01</td>
<td align="right">9.700000e-01</td>
<td align="right">1.000000e+00</td>
<td align="left">▁▅▃▇▆</td>
</tr>
<tr class="odd">
<td align="left">lgsize</td>
<td align="left">4</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.436000e+01</td>
<td align="right">4.090000e+00</td>
<td align="right">7.620000e+00</td>
<td align="right">1.08300e+01</td>
<td align="right">1.386000e+01</td>
<td align="right">1.775000e+01</td>
<td align="right">2.368000e+01</td>
<td align="left">▇▇▆▇▂</td>
</tr>
<tr class="even">
<td align="left">sqrtlast_updated</td>
<td align="left">4</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3.819000e+01</td>
<td align="right">9.360000e+00</td>
<td align="right">1.801000e+01</td>
<td align="right">2.99600e+01</td>
<td align="right">4.181000e+01</td>
<td align="right">4.525000e+01</td>
<td align="right">4.935000e+01</td>
<td align="left">▂▃▂▃▇</td>
</tr>
<tr class="odd">
<td align="left">size</td>
<td align="left">5</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.944792e+08</td>
<td align="right">1.010925e+09</td>
<td align="right">1.600000e+02</td>
<td align="right">2.35520e+04</td>
<td align="right">3.799040e+05</td>
<td align="right">9.437184e+06</td>
<td align="right">2.040109e+10</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">last_updated</td>
<td align="left">5</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5.149300e+02</td>
<td align="right">3.848600e+02</td>
<td align="right">2.000000e-02</td>
<td align="right">1.90440e+02</td>
<td align="right">4.157100e+02</td>
<td align="right">8.233200e+02</td>
<td align="right">1.782590e+03</td>
<td align="left">▇▅▃▂▁</td>
</tr>
<tr class="odd">
<td align="left">download_count</td>
<td align="left">5</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.681810e+03</td>
<td align="right">5.968200e+03</td>
<td align="right">1.000000e+01</td>
<td align="right">5.10000e+02</td>
<td align="right">1.058000e+03</td>
<td align="right">2.253500e+03</td>
<td align="right">1.033810e+05</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">vote_count</td>
<td align="left">5</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">6.993000e+01</td>
<td align="right">1.333300e+02</td>
<td align="right">2.200000e+01</td>
<td align="right">2.90000e+01</td>
<td align="right">3.700000e+01</td>
<td align="right">5.900000e+01</td>
<td align="right">1.965000e+03</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">usability_rating</td>
<td align="left">5</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">9.700000e-01</td>
<td align="right">4.000000e-02</td>
<td align="right">8.500000e-01</td>
<td align="right">9.40000e-01</td>
<td align="right">1.000000e+00</td>
<td align="right">1.000000e+00</td>
<td align="right">1.000000e+00</td>
<td align="left">▁▁▁▂▇</td>
</tr>
<tr class="even">
<td align="left">lgsize</td>
<td align="left">5</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.329000e+01</td>
<td align="right">4.000000e+00</td>
<td align="right">5.080000e+00</td>
<td align="right">1.00700e+01</td>
<td align="right">1.285000e+01</td>
<td align="right">1.606000e+01</td>
<td align="right">2.374000e+01</td>
<td align="left">▃▇▇▅▂</td>
</tr>
<tr class="odd">
<td align="left">sqrtlast_updated</td>
<td align="left">5</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.077000e+01</td>
<td align="right">9.140000e+00</td>
<td align="right">1.400000e-01</td>
<td align="right">1.38000e+01</td>
<td align="right">2.039000e+01</td>
<td align="right">2.869000e+01</td>
<td align="right">4.222000e+01</td>
<td align="left">▃▇▇▇▂</td>
</tr>
</tbody>
</table>
<p>There’s no obvious groupings but size, votes, and downloads seems to
group the data a fair bit. We will fit a model with this transformed
data and see if we have any better performance</p>
</div>
<div id="section-same-model-but-different-data" class="section level3">
<h3>Same Model But Different (Data)</h3>
<pre class="r"><code>library(tidymodels)
library(tidyselect)
# Pulling from https://www.tidymodels.org/start/case-study/
set.seed(42723)
splits      = initial_split(kaggle_clustered)

kaggle_other = training(splits)
kaggle_test  = testing(splits)

val_set = validation_split(kaggle_other, 
                            prop = 0.80)

lr_mod = logistic_reg(penalty = tune(), mixture = 1) %&gt;% 
  set_engine(&quot;glmnet&quot;)

lr_recipe = recipe(popularity ~ title_class + lgsize + usability + sqrtlast_updated + cluster,
                   data = kaggle_other) %&gt;% 
  step_dummy(all_nominal_predictors()) %&gt;% 
  step_zv(all_predictors()) %&gt;% 
  step_normalize()

lr_workflow =  workflow() %&gt;% 
  add_model(lr_mod) %&gt;% 
  add_recipe(lr_recipe)

lr_reg_grid = tibble(penalty = 10^seq(-4, -1, length.out = 30))

lr_reg_grid %&gt;% top_n(-5)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["penalty"],"name":[1],"type":["dbl"],"align":["right"]}],"data":[{"1":"0.0001000000"},{"1":"0.0001268961"},{"1":"0.0001610262"},{"1":"0.0002043360"},{"1":"0.0002592944"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>lr_reg_grid %&gt;% top_n(5)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["penalty"],"name":[1],"type":["dbl"],"align":["right"]}],"data":[{"1":"0.03856620"},{"1":"0.04893901"},{"1":"0.06210169"},{"1":"0.07880463"},{"1":"0.10000000"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>lr_res = lr_workflow %&gt;% 
  tune_grid(val_set,
            grid = lr_reg_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))
lr_plot =
  lr_res %&gt;% 
  collect_metrics() %&gt;% 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  ylab(&quot;Area under the ROC Curve&quot;) +
  scale_x_log10(labels = scales::label_number())

lr_plot</code></pre>
<p><img src="final_project_tutorial_files/figure-html/big_ol_log2-1.png" width="624" /></p>
<pre class="r"><code>top_models &lt;-
  lr_res %&gt;% 
  show_best(&quot;roc_auc&quot;, n = 15) %&gt;% 
  arrange(penalty) 
top_models</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["penalty"],"name":[1],"type":["dbl"],"align":["right"]},{"label":[".metric"],"name":[2],"type":["chr"],"align":["left"]},{"label":[".estimator"],"name":[3],"type":["chr"],"align":["left"]},{"label":["mean"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["n"],"name":[5],"type":["int"],"align":["right"]},{"label":["std_err"],"name":[6],"type":["dbl"],"align":["right"]},{"label":[".config"],"name":[7],"type":["chr"],"align":["left"]}],"data":[{"1":"0.0001000000","2":"roc_auc","3":"binary","4":"0.6518317","5":"1","6":"NA","7":"Preprocessor1_Model01"},{"1":"0.0001268961","2":"roc_auc","3":"binary","4":"0.6518317","5":"1","6":"NA","7":"Preprocessor1_Model02"},{"1":"0.0001610262","2":"roc_auc","3":"binary","4":"0.6518317","5":"1","6":"NA","7":"Preprocessor1_Model03"},{"1":"0.0002043360","2":"roc_auc","3":"binary","4":"0.6518317","5":"1","6":"NA","7":"Preprocessor1_Model04"},{"1":"0.0002592944","2":"roc_auc","3":"binary","4":"0.6518317","5":"1","6":"NA","7":"Preprocessor1_Model05"},{"1":"0.0003290345","2":"roc_auc","3":"binary","4":"0.6518317","5":"1","6":"NA","7":"Preprocessor1_Model06"},{"1":"0.0004175319","2":"roc_auc","3":"binary","4":"0.6518317","5":"1","6":"NA","7":"Preprocessor1_Model07"},{"1":"0.0005298317","2":"roc_auc","3":"binary","4":"0.6518655","5":"1","6":"NA","7":"Preprocessor1_Model08"},{"1":"0.0006723358","2":"roc_auc","3":"binary","4":"0.6518746","5":"1","6":"NA","7":"Preprocessor1_Model09"},{"1":"0.0008531679","2":"roc_auc","3":"binary","4":"0.6517799","5":"1","6":"NA","7":"Preprocessor1_Model10"},{"1":"0.0010826367","2":"roc_auc","3":"binary","4":"0.6516265","5":"1","6":"NA","7":"Preprocessor1_Model11"},{"1":"0.0013738238","2":"roc_auc","3":"binary","4":"0.6516400","5":"1","6":"NA","7":"Preprocessor1_Model12"},{"1":"0.0017433288","2":"roc_auc","3":"binary","4":"0.6514574","5":"1","6":"NA","7":"Preprocessor1_Model13"},{"1":"0.0022122163","2":"roc_auc","3":"binary","4":"0.6511642","5":"1","6":"NA","7":"Preprocessor1_Model14"},{"1":"0.0028072162","2":"roc_auc","3":"binary","4":"0.6508011","5":"1","6":"NA","7":"Preprocessor1_Model15"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>lr_best =
  lr_res %&gt;% 
  collect_metrics() %&gt;% 
  arrange(penalty) %&gt;% 
  slice(17)
lr_best</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["penalty"],"name":[1],"type":["dbl"],"align":["right"]},{"label":[".metric"],"name":[2],"type":["chr"],"align":["left"]},{"label":[".estimator"],"name":[3],"type":["chr"],"align":["left"]},{"label":["mean"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["n"],"name":[5],"type":["int"],"align":["right"]},{"label":["std_err"],"name":[6],"type":["dbl"],"align":["right"]},{"label":[".config"],"name":[7],"type":["chr"],"align":["left"]}],"data":[{"1":"0.004520354","2":"roc_auc","3":"binary","4":"0.6498833","5":"1","6":"NA","7":"Preprocessor1_Model17"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>lr_auc = lr_res %&gt;% 
  collect_predictions(parameters = lr_best) %&gt;% 
  roc_curve(popularity, &quot;.pred_Not Popular&quot;) %&gt;% 
  mutate(model = &quot;Logistic Regression&quot;)

autoplot(lr_auc)</code></pre>
<p><img src="final_project_tutorial_files/figure-html/big_ol_log2-2.png" width="624" /></p>
<p>Our best model has a mean ROC-AUC metric of 0.65 which is pretty
great given that we were dealing with a 0.5 which was meaningless
earlier. This shows us that we have a model now which can make some kind
of informed guess about a record’s popularity. We could tinker to try to
bring the ROC-AUC above 0.75 but I tried a random forest to no avail, so
I think this is a nice place to stop.</p>
</div>
</div>
<div id="section-reflecting-on-iteration-2" class="section level2">
<h2>Reflecting On Iteration 2</h2>
<p>By using more standard preprocessing and common sense fixes, we were
able to use our data to squeeze some insight out of the model. We do
still need to make a final conclusion, but I would say we have hit all
the course objectives.</p>
</div>
<div id="section-concluding-concluding-concluding"
class="section level2">
<h2>Concluding Concluding Concluding</h2>
<p>I would like to conclude by explaining how to conclude something when
you conclude your project. I will stop having fun with this meta now.
You starting with a question lends itself to a nice conclusion which
restates the question with a truth value somewhere. Our original
question, “What data do people create datasets on Kaggle to analyze?”
The answer is that according to a dataset we built from information
about their top 10,000 records by vote, we can model how likely that
dataset is to be popular given what we know about it.</p>
<p>We can see from the ROC-AUC curve that around two-thirds of the time
our model can guess what will be popular and we would like to report
what it is getting wrong.</p>
<pre class="r"><code>lr_preds = lr_res %&gt;% 
  collect_predictions(parameters = lr_best) %&gt;% 
  mutate(popularity_preds = ifelse(.pred_Popular &gt;= 0.5, &quot;Popular&quot;, &quot;Not Popular&quot;))

fp_index = lr_preds$.row[(lr_preds$popularity_preds != lr_preds$popularity) &amp;
                           (lr_preds$popularity_preds == &quot;Popular&quot;)]
kaggle_other[fp_index,] %&gt;% 
  skim()</code></pre>
<table>
<caption>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">Piped data</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">212</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">12</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">factor</td>
<td align="left">4</td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">7</td>
</tr>
<tr class="odd">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<colgroup>
<col width="19%" />
<col width="13%" />
<col width="19%" />
<col width="5%" />
<col width="5%" />
<col width="8%" />
<col width="12%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">title</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">6</td>
<td align="right">50</td>
<td align="right">0</td>
<td align="right">212</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<colgroup>
<col width="15%" />
<col width="11%" />
<col width="15%" />
<col width="8%" />
<col width="10%" />
<col width="38%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">title_class</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">16</td>
<td align="left">new: 47, No : 41, fit: 31, bus: 20</td>
</tr>
<tr class="even">
<td align="left">popularity</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">1</td>
<td align="left">Not: 212, Pop: 0</td>
</tr>
<tr class="odd">
<td align="left">usability</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Usa: 113, Hig: 99</td>
</tr>
<tr class="even">
<td align="left">cluster</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">4</td>
<td align="left">5: 118, 3: 84, 2: 7, 1: 3</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<colgroup>
<col width="13%" />
<col width="7%" />
<col width="11%" />
<col width="10%" />
<col width="10%" />
<col width="5%" />
<col width="7%" />
<col width="8%" />
<col width="10%" />
<col width="10%" />
<col width="4%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">size</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.104907e+09</td>
<td align="right">6.047578e+09</td>
<td align="right">428.00</td>
<td align="right">118784.00</td>
<td align="right">3145728.00</td>
<td align="right">142868480.00</td>
<td align="right">7.730941e+10</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">last_updated</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.260580e+03</td>
<td align="right">5.440800e+02</td>
<td align="right">230.27</td>
<td align="right">911.80</td>
<td align="right">1165.81</td>
<td align="right">1641.64</td>
<td align="right">2.416630e+03</td>
<td align="left">▆▇▇▅▅</td>
</tr>
<tr class="odd">
<td align="left">download_count</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.268380e+03</td>
<td align="right">1.119800e+03</td>
<td align="right">20.00</td>
<td align="right">623.25</td>
<td align="right">1076.00</td>
<td align="right">1635.00</td>
<td align="right">1.052300e+04</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">vote_count</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.891000e+01</td>
<td align="right">4.960000e+00</td>
<td align="right">22.00</td>
<td align="right">25.00</td>
<td align="right">28.00</td>
<td align="right">33.00</td>
<td align="right">3.800000e+01</td>
<td align="left">▇▅▃▃▅</td>
</tr>
<tr class="odd">
<td align="left">usability_rating</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">8.700000e-01</td>
<td align="right">1.300000e-01</td>
<td align="right">0.53</td>
<td align="right">0.76</td>
<td align="right">0.92</td>
<td align="right">1.00</td>
<td align="right">1.000000e+00</td>
<td align="left">▁▂▂▃▇</td>
</tr>
<tr class="even">
<td align="left">lgsize</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.514000e+01</td>
<td align="right">4.320000e+00</td>
<td align="right">6.06</td>
<td align="right">11.68</td>
<td align="right">14.96</td>
<td align="right">18.77</td>
<td align="right">2.507000e+01</td>
<td align="left">▃▇▇▆▃</td>
</tr>
<tr class="odd">
<td align="left">sqrtlast_updated</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3.460000e+01</td>
<td align="right">7.970000e+00</td>
<td align="right">15.17</td>
<td align="right">30.20</td>
<td align="right">34.14</td>
<td align="right">40.52</td>
<td align="right">4.916000e+01</td>
<td align="left">▁▃▇▆▅</td>
</tr>
</tbody>
</table>
<pre class="r"><code>kaggle_other[fp_index,] %&gt;% 
  tabyl(title_class) %&gt;% 
  arrange(n)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["title_class"],"name":[1],"type":["fct"],"align":["left"]},{"label":["n"],"name":[2],"type":["int"],"align":["right"]},{"label":["percent"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"family","2":"0","3":"0.000000000"},{"1":"other_hobbies","2":"0","3":"0.000000000"},{"1":"relationships","2":"0","3":"0.000000000"},{"1":"fashion_&_style","2":"1","3":"0.004716981"},{"1":"arts_&_culture","2":"2","3":"0.009433962"},{"1":"film_tv_&_video","2":"2","3":"0.009433962"},{"1":"travel_&_adventure","2":"3","3":"0.014150943"},{"1":"diaries_&_daily_life","2":"4","3":"0.018867925"},{"1":"food_&_dining","2":"5","3":"0.023584906"},{"1":"gaming","2":"5","3":"0.023584906"},{"1":"celebrity_&_pop_culture","2":"7","3":"0.033018868"},{"1":"learning_&_educational","2":"7","3":"0.033018868"},{"1":"music","2":"9","3":"0.042452830"},{"1":"sports","2":"13","3":"0.061320755"},{"1":"science_&_technology","2":"15","3":"0.070754717"},{"1":"business_&_entrepreneurs","2":"20","3":"0.094339623"},{"1":"fitness_&_health","2":"31","3":"0.146226415"},{"1":"No Class","2":"41","3":"0.193396226"},{"1":"news_&_social_concern","2":"47","3":"0.221698113"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>fn_index = lr_preds$.row[(lr_preds$popularity_preds != lr_preds$popularity) &amp;
                           (lr_preds$popularity_preds == &quot;Not Popular&quot;)]
kaggle_other[fn_index,] %&gt;% 
  skim()</code></pre>
<table>
<caption>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">Piped data</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">300</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">12</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">factor</td>
<td align="left">4</td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">7</td>
</tr>
<tr class="odd">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<colgroup>
<col width="19%" />
<col width="13%" />
<col width="19%" />
<col width="5%" />
<col width="5%" />
<col width="8%" />
<col width="12%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">title</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">8</td>
<td align="right">50</td>
<td align="right">0</td>
<td align="right">299</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<colgroup>
<col width="15%" />
<col width="11%" />
<col width="15%" />
<col width="8%" />
<col width="10%" />
<col width="38%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">title_class</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">17</td>
<td align="left">bus: 62, new: 52, No : 44, fit: 24</td>
</tr>
<tr class="even">
<td align="left">popularity</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">1</td>
<td align="left">Pop: 300, Not: 0</td>
</tr>
<tr class="odd">
<td align="left">usability</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Hig: 179, Usa: 121</td>
</tr>
<tr class="even">
<td align="left">cluster</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">3</td>
<td align="left">5: 208, 2: 90, 1: 2, 3: 0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<colgroup>
<col width="13%" />
<col width="8%" />
<col width="11%" />
<col width="10%" />
<col width="10%" />
<col width="5%" />
<col width="7%" />
<col width="8%" />
<col width="8%" />
<col width="10%" />
<col width="4%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">size</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">546256577.85</td>
<td align="right">2.983121e+09</td>
<td align="right">831.00</td>
<td align="right">23296.00</td>
<td align="right">311296.00</td>
<td align="right">8388608.00</td>
<td align="right">3.758096e+10</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">last_updated</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">426.48</td>
<td align="right">3.417800e+02</td>
<td align="right">0.40</td>
<td align="right">159.27</td>
<td align="right">338.43</td>
<td align="right">618.05</td>
<td align="right">1.287090e+03</td>
<td align="left">▇▆▂▂▂</td>
</tr>
<tr class="odd">
<td align="left">download_count</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3656.89</td>
<td align="right">7.500480e+03</td>
<td align="right">40.00</td>
<td align="right">874.25</td>
<td align="right">1816.50</td>
<td align="right">3641.00</td>
<td align="right">1.033810e+05</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">vote_count</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">99.99</td>
<td align="right">1.884500e+02</td>
<td align="right">39.00</td>
<td align="right">45.00</td>
<td align="right">57.50</td>
<td align="right">81.25</td>
<td align="right">1.965000e+03</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">usability_rating</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.90</td>
<td align="right">1.300000e-01</td>
<td align="right">0.53</td>
<td align="right">0.82</td>
<td align="right">0.97</td>
<td align="right">1.00</td>
<td align="right">1.000000e+00</td>
<td align="left">▁▁▁▂▇</td>
</tr>
<tr class="even">
<td align="left">lgsize</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">13.44</td>
<td align="right">4.170000e+00</td>
<td align="right">6.72</td>
<td align="right">10.06</td>
<td align="right">12.65</td>
<td align="right">15.94</td>
<td align="right">2.435000e+01</td>
<td align="left">▆▇▆▃▂</td>
</tr>
<tr class="odd">
<td align="left">sqrtlast_updated</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">18.84</td>
<td align="right">8.470000e+00</td>
<td align="right">0.63</td>
<td align="right">12.62</td>
<td align="right">18.40</td>
<td align="right">24.86</td>
<td align="right">3.588000e+01</td>
<td align="left">▂▆▇▃▃</td>
</tr>
</tbody>
</table>
<pre class="r"><code>kaggle_other[fn_index,] %&gt;% 
  tabyl(title_class) %&gt;% 
  arrange(n)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["title_class"],"name":[1],"type":["fct"],"align":["left"]},{"label":["n"],"name":[2],"type":["int"],"align":["right"]},{"label":["percent"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"family","2":"0","3":"0.000000000"},{"1":"relationships","2":"0","3":"0.000000000"},{"1":"other_hobbies","2":"1","3":"0.003333333"},{"1":"celebrity_&_pop_culture","2":"2","3":"0.006666667"},{"1":"arts_&_culture","2":"3","3":"0.010000000"},{"1":"fashion_&_style","2":"3","3":"0.010000000"},{"1":"music","2":"4","3":"0.013333333"},{"1":"food_&_dining","2":"6","3":"0.020000000"},{"1":"travel_&_adventure","2":"6","3":"0.020000000"},{"1":"diaries_&_daily_life","2":"9","3":"0.030000000"},{"1":"gaming","2":"11","3":"0.036666667"},{"1":"learning_&_educational","2":"14","3":"0.046666667"},{"1":"sports","2":"19","3":"0.063333333"},{"1":"film_tv_&_video","2":"20","3":"0.066666667"},{"1":"science_&_technology","2":"20","3":"0.066666667"},{"1":"fitness_&_health","2":"24","3":"0.080000000"},{"1":"No Class","2":"44","3":"0.146666667"},{"1":"news_&_social_concern","2":"52","3":"0.173333333"},{"1":"business_&_entrepreneurs","2":"62","3":"0.206666667"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>We can see the model is overly favorable to news and social concerns
and non-classified (original) ideas. It is generally wrong about
business and entrepeneur related data. From this, we could draw a more
specific answer to our question that the most popular datasets to
construct on Kaggle are social topics of discussion or finance related,
but there is a powerful group of original datasets which do not fit into
the broader categories we tested. It is this orignality which I believe
you would be wisest to tap into, but if you are going to lean on some
existing ideas then I would suggest popular socioeconomic topics as a
good starting point for gaining traction. It is important that you find
ways to wrap your work into a clean report with a good conclusion at the
end unless of course your report is on report writing. In which case, I
lean on the layers of abstraction about exposing my process to justify
leaving in less useful results and explorations. I hope you found this
useful and thank you to Bradford for all the things you have taught us
and all the kindness you have shown us. 
<script type="application/shiny-prerendered" data-context="server-start">
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	root.dir = "final_project"
)
library(learnr)
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = NULL)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::prepare_tutorial_state(session)
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::i18n_observe_tutorial_language(input, session)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
session$onSessionEnded(function() {
        learnr:::event_trigger(session, "session_stop")
      })
</script>
</p>
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["header-attrs"]},{"type":"character","attributes":{},"value":["2.21"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pandoc"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["header-attrs.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.21"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"character","attributes":{},"value":["<style>h1 {font-size: 34px;}\n       h1.title {font-size: 38px;}\n       h2 {font-size: 30px;}\n       h3 {font-size: 24px;}\n       h4 {font-size: 18px;}\n       h5 {font-size: 16px;}\n       h6 {font-size: 12px;}\n       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}\n       pre:not([class]) { background-color: white }<\/style>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.21"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.21"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.21"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.3"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["i18n"]},{"type":"character","attributes":{},"value":["21.6.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/i18n"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["i18next.min.js","tutorial-i18n-init.js"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["<script id=\"i18n-cstm-trns\" type=\"application/json\">{\"language\":\"en\",\"resources\":{\"en\":{\"translation\":{\"button\":{\"runcode\":\"Run Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Hint\",\"hint_plural\":\"Hints\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Next Hint\",\"hintprev\":\"Previous Hint\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copy to Clipboard\",\"startover\":\"Start Over\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continue\",\"submitanswer\":\"Submit Answer\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Previous Topic\",\"nexttopic\":\"Next Topic\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Try Again\"},\"text\":{\"startover\":\"Start Over\",\"areyousure\":\"Are you sure you want to start over? (all exercise progress will be reset)\",\"youmustcomplete\":\"You must complete the\",\"exercise\":\"exercise\",\"exercise_plural\":\"exercises\",\"inthissection\":\"in this section before continuing.\",\"code\":\"Code\",\"enginecap\":\"{{engine}} $t(text.code)\",\"quiz\":\"Quiz\",\"blank\":\"blank\",\"blank_plural\":\"blanks\",\"exercisecontainsblank\":\"This exercise contains {{count}} $t(text.blank).\",\"pleasereplaceblank\":\"Please replace {{blank}} with valid code.\",\"unparsable\":\"It looks like this might not be valid R code. R cannot determine how to turn your text into a complete command. You may have forgotten to fill in a blank, to remove an underscore, to include a comma between arguments, or to close an opening <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> or <code>{<\\/code> with a matching <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> or <code>}<\\/code>.\\n\",\"unparsablequotes\":\"<p>It looks like your R code contains specially formatted quotation marks or &quot;curly&quot; quotes (<code>{{character}}<\\/code>) around character strings, making your code invalid. R requires character values to be contained in straight quotation marks (<code>&quot;<\\/code> or <code>'<\\/code>).<\\/p> {{code}} <p>Don't worry, this is a common source of errors when you copy code from another app that applies its own formatting to text. You can try replacing the code on that line with the following. There may be other places that need to be fixed, too.<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>It looks like your R code contains an unexpected special character (<code>{{character}}<\\/code>) that makes your code invalid.<\\/p> {{code}} <p>Sometimes your code may contain a special character that looks like a regular character, especially if you copy and paste the code from another app. Try deleting the special character from your code and retyping it manually.<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>It looks like your R code contains an unexpected special character (<code>{{character}}<\\/code>) that makes your code invalid.<\\/p> {{code}} <p>Sometimes your code may contain a special character that looks like a regular character, especially if you copy and paste the code from another app. You can try replacing the code on that line with the following. There may be other places that need to be fixed, too.<\\/p> {{suggestion}}\\n\",\"and\":\"and\",\"or\":\"or\",\"listcomma\":\", \",\"oxfordcomma\":\",\"}}},\"fr\":{\"translation\":{\"button\":{\"runcode\":\"Lancer le Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Indication\",\"hint_plural\":\"Indications\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Indication Suivante\",\"hintprev\":\"Indication Précédente\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copier dans le Presse-papier\",\"startover\":\"Recommencer\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuer\",\"submitanswer\":\"Soumettre\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Chapitre Précédent\",\"nexttopic\":\"Chapitre Suivant\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Réessayer\"},\"text\":{\"startover\":\"Recommencer\",\"areyousure\":\"Êtes-vous certains de vouloir recommencer? (La progression sera remise à zéro)\",\"youmustcomplete\":\"Vous devez d'abord compléter\",\"exercise\":\"l'exercice\",\"exercise_plural\":\"des exercices\",\"inthissection\":\"de cette section avec de continuer.\",\"code\":\"Code\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"and\":\"et\",\"or\":\"ou\",\"oxfordcomma\":\"\"}}},\"es\":{\"translation\":{\"button\":{\"runcode\":\"Ejecutar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Pista\",\"hint_plural\":\"Pistas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Siguiente pista\",\"hintprev\":\"Pista anterior\",\"solution\":\"Solución\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar al portapapeles\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar respuesta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tema anterior\",\"nexttopic\":\"Tema siguiente\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Volver a intentar\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"¿De verdad quieres empezar de nuevo? (todo el progreso del ejercicio se perderá)\",\"youmustcomplete\":\"Debes completar\",\"exercise\":\"el ejercicio\",\"exercise_plural\":\"los ejercicios\",\"inthissection\":\"en esta sección antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Cuestionario\",\"and\":\"y\",\"or\":\"o\",\"oxfordcomma\":\"\"}}},\"pt\":{\"translation\":{\"button\":{\"runcode\":\"Executar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Dica\",\"hint_plural\":\"Dicas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Próxima dica\",\"hintprev\":\"Dica anterior\",\"solution\":\"Solução\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar para a área de transferência\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar resposta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tópico anterior\",\"nexttopic\":\"Próximo tópico\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tentar novamente\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"Tem certeza que deseja começar novamente? (todo o progresso feito será perdido)\",\"youmustcomplete\":\"Você deve completar\",\"exercise\":\"o exercício\",\"exercise_plural\":\"os exercícios\",\"inthissection\":\"nesta seção antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"and\":\"e\",\"or\":\"ou\",\"oxfordcomma\":\"\"}}},\"tr\":{\"translation\":{\"button\":{\"runcode\":\"Çalıştırma Kodu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Ipucu\",\"hint_plural\":\"İpuçları\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Sonraki İpucu\",\"hintprev\":\"Önceki İpucu\",\"solution\":\"Çözüm\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Pano'ya Kopyala\",\"startover\":\"Baştan Başlamak\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Devam et\",\"submitanswer\":\"Cevabı onayla\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Önceki Konu\",\"nexttopic\":\"Sonraki Konu\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tekrar Deneyin\"},\"text\":{\"startover\":\"Baştan Başlamak\",\"areyousure\":\"Baştan başlamak istediğinizden emin misiniz? (tüm egzersiz ilerlemesi kaybolacak)\",\"youmustcomplete\":\"Tamamlamalısın\",\"exercise\":\"egzersiz\",\"exercise_plural\":\"egzersizler\",\"inthissection\":\"devam etmeden önce bu bölümde\",\"code\":\"Kod\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Sınav\",\"oxfordcomma\":\"\"}}},\"emo\":{\"translation\":{\"button\":{\"runcode\":\"🏃\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"💡\",\"hint_plural\":\"$t(button.hint)\",\"hinttitle\":\"$t(button.hint)\",\"solution\":\"🎯\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"📋\",\"startover\":\"⏮\",\"startovertitle\":\"Start Over\",\"continue\":\"✅\",\"submitanswer\":\"🆗\",\"submitanswertitle\":\"Submit Answer\",\"previoustopic\":\"⬅\",\"nexttopic\":\"➡\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"🔁\"},\"text\":{\"startover\":\"⏮\",\"areyousure\":\"🤔\",\"youmustcomplete\":\"⚠️ 👉 🧑‍💻\",\"exercise\":\"\",\"exercise_plural\":\"\",\"inthissection\":\"\",\"code\":\"💻\",\"enginecap\":\"$t(text.code) {{engine}}\",\"oxfordcomma\":\"\"}}},\"eu\":{\"translation\":{\"button\":{\"runcode\":\"Kodea egikaritu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Laguntza\",\"hint_plural\":\"Laguntza\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Aurreko laguntza\",\"hintprev\":\"Hurrengo laguntza\",\"solution\":\"Ebazpena\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Arbelean kopiatu\",\"startover\":\"Berrabiarazi\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Jarraitu\",\"submitanswer\":\"Erantzuna bidali\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Aurreko atala\",\"nexttopic\":\"Hurrengo atala\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Berriro saiatu\"},\"text\":{\"startover\":\"Berrabiarazi\",\"areyousure\":\"Berriro hasi nahi duzu? (egindako lana galdu egingo da)\",\"youmustcomplete\":\"Aurrera egin baino lehen atal honetako\",\"exercise\":\"ariketa egin behar duzu.\",\"exercise_plural\":\"ariketak egin behar dituzu.\",\"inthissection\":\"\",\"code\":\"Kodea\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Galdetegia\",\"oxfordcomma\":\"\"}}},\"de\":{\"translation\":{\"button\":{\"runcode\":\"Code ausführen\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Tipp\",\"hint_plural\":\"Tipps\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Nächster Tipp\",\"hintprev\":\"Vorheriger Tipp\",\"solution\":\"Lösung\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"In die Zwischenablage kopieren\",\"startover\":\"Neustart\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Weiter\",\"submitanswer\":\"Antwort einreichen\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Vorheriges Kapitel\",\"nexttopic\":\"Nächstes Kapitel\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Nochmal versuchen\"},\"text\":{\"startover\":\"Neustart\",\"areyousure\":\"Bist du sicher, dass du neustarten willst? (der gesamte Lernfortschritt wird gelöscht)\",\"youmustcomplete\":\"Vervollstädinge\",\"exercise\":\"die Übung\",\"exercise_plural\":\"die Übungen\",\"inthissection\":\"in diesem Kapitel, bevor du fortfährst.\",\"code\":\"Code\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"blank\":\"Lücke\",\"blank_plural\":\"Lücken\",\"pleasereplaceblank\":\"Bitte ersetze {{blank}} mit gültigem Code.\",\"unparsable\":\"Dies scheint kein gültiger R Code zu sein. R kann deinen Text nicht in einen gültigen Befehl übersetzen. Du hast vielleicht vergessen, die Lücke zu füllen, einen Unterstrich zu entfernen, ein Komma zwischen Argumente zu setzen oder ein eröffnendes <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> oder <code>{<\\/code> mit einem zugehörigen <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> oder <code>}<\\/code> zu schließen.\\n\",\"and\":\"und\",\"or\":\"oder\",\"listcomma\":\", \",\"oxfordcomma\":\",\"}}},\"ko\":{\"translation\":{\"button\":{\"runcode\":\"코드 실행\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"힌트\",\"hint_plural\":\"힌트들\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"다음 힌트\",\"hintprev\":\"이전 힌트\",\"solution\":\"솔루션\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"클립보드에 복사\",\"startover\":\"재학습\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"다음 학습으로\",\"submitanswer\":\"정답 제출\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"이전 토픽\",\"nexttopic\":\"다음 토픽\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"재시도\"},\"text\":{\"startover\":\"재학습\",\"areyousure\":\"다시 시작 하시겠습니까? (모든 예제의 진행 정보가 재설정됩니다)\",\"youmustcomplete\":\"당신은 완료해야 합니다\",\"exercise\":\"연습문제\",\"exercise_plural\":\"연습문제들\",\"inthissection\":\"이 섹션을 실행하기 전에\",\"code\":\"코드\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"퀴즈\",\"blank\":\"공백\",\"blank_plural\":\"공백들\",\"exercisecontainsblank\":\"이 연습문제에는 {{count}}개의 $t(text.blank)이 포함되어 있습니다.\",\"pleasereplaceblank\":\"{{blank}}를 유효한 코드로 바꾸십시오.\",\"unparsable\":\"이것은 유효한 R 코드가 아닐 수 있습니다. R은 텍스트를 완전한 명령으로 변환하는 방법을 결정할 수 없습니다. 당신은 공백이나 밑줄을 대체하여 채우기, 인수를 컴마로 구분하기, 또는 <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> , <code>{<\\/code>로 시작하는 구문을 닫는 <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code>, <code>}<\\/code>을 잊었을 수도 있습니다.\\n\",\"and\":\"그리고\",\"or\":\"혹은\",\"listcomma\":\", \",\"oxfordcomma\":\"\"}}},\"zh\":{\"translation\":{\"button\":{\"runcode\":\"运行代码\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"提示\",\"hint_plural\":\"提示\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"下一个提示\",\"hintprev\":\"上一个提示\",\"solution\":\"答案\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"复制到剪切板\",\"startover\":\"重新开始\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"继续\",\"submitanswer\":\"提交答案\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"上一专题\",\"nexttopic\":\"下一专题\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"再试一次\"},\"text\":{\"startover\":\"重置\",\"areyousure\":\"你确定要重新开始吗? (所有当前进度将被重置)\",\"youmustcomplete\":\"你必须完成\",\"exercise\":\"练习\",\"exercise_plural\":\"练习\",\"inthissection\":\"在进行本节之前\",\"code\":\"代码\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"测试\",\"blank\":\"空\",\"blank_plural\":\"空\",\"exercisecontainsblank\":\"本练习包含{{count}}个$t(text.blank)\",\"pleasereplaceblank\":\"请在{{blank}}内填写恰当的代码\",\"unparsable\":\"这似乎不是有效的R代码。 R不知道如何将您的文本转换为完整的命令。 您是否忘了填空，忘了删除下划线，忘了在参数之间包含逗号，或者是忘了用<code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code>,<code>}<\\/code>来封闭<code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code>。 or <code>{<\\/code>。\\n\",\"unparsablequotes\":\"<p>您的R代码中似乎含有特殊格式的引号，或者弯引号(<code>{{character}}<\\/code>) 在字符串前后，在R中字符串应该被直引号(<code>&quot;<\\/code> 或者 <code>'<\\/code>)包裹。<\\/p> {{code}} <p>别担心，该错误经常在复制粘贴包含格式的代码时遇到， 您可以尝试将该行中的代码替换为以下代码，也许还有其他地方需要修改。<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>您的代码中似乎包含有异常字符(<code>{{character}}<\\/code>),导致代码无效。<\\/p> {{code}} <p>有时候你的代码可能含有看似正常字符的特殊字符，特别是当你复制粘贴其他来源代码的时候。 请试着删除这些特殊字符,重新输入<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>您的代码中似乎包含有异常字符(<code>{{character}}<\\/code>),导致代码无效。<\\/p> {{code}} <p>有时候你的代码可能含有看似正常字符的特殊字符，特别是当你复制粘贴其他来源代码的时候。 请试着删除这些特殊字符,重新输入<\\/p>\\n\",\"and\":\"且\",\"or\":\"或\",\"listcomma\":\",\",\"oxfordcomma\":\",\"}}},\"pl\":{\"translation\":{\"button\":{\"runcode\":\"Uruchom kod\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Podpowiedź\",\"hint_plural\":\"Podpowiedzi\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Następna podpowiedź\",\"hintprev\":\"Poprzednia podpowiedź\",\"solution\":\"Rozwiązanie\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Kopiuj do schowka\",\"startover\":\"Zacznij od początku\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Kontynuuj\",\"submitanswer\":\"Wyślij\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Poprzednia sekcja\",\"nexttopic\":\"Następna sekcja\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Spróbuj ponownie\"},\"text\":{\"startover\":\"Zacznij od początku\",\"areyousure\":\"Czy na pewno chcesz zacząć od początku? (cały postęp w zadaniu zostanie utracony)\",\"youmustcomplete\":\"Musisz ukończyć\",\"exercise\":\"ćwiczenie\",\"exercise_plural\":\"ćwiczenia\",\"inthissection\":\"w tej sekcji przed kontynuowaniem\",\"code\":\"Kod\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"blank\":\"luka\",\"blank_plural\":\"luk(i)\",\"exercisecontainsblank\":\"To ćwiczenie zawiera {{count}} $t(text.blank).\",\"pleasereplaceblank\":\"Proszę uzupełnić {{blank}} prawidłowym kodem.\",\"unparsable\":\"Wygląda na to, że może to nie być prawidłowy kod R. R nie jest w stanie przetworzyć Twojego tekstu na polecenie. Mogłeś(-aś) zapomnieć wypełnić luki, usunąć podkreślnik, umieścić przecinka między argumentami, lub zamknąć znak <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> lub <code>{<\\/code> odpowiadającym <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> lub <code>}<\\/code>.\\n\",\"unparsablequotes\":\"<p>Wygląda na to, że Twój kod zawiera szczególnie sformatowane cudzysłowy lub cudzysłowy typograficzne (<code>{{character}}<\\/code>) przy ciągach znaków, co sprawia, że kod jest niepoprawny. R wymaga cudzysłowów prostych (<code>&quot;<\\/code> albo <code>'<\\/code>).<\\/p> {{code}} <p>Nie martw się, to powszechne źródło błędów, gdy kopiuje się kod z innego programu, który sam formatuje teskt. Możesz spróbować zastąpić swój kod następującym kodem. Mogą być też inne miejsca, które wymagają poprawienia.<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>Wygląda na to, że Twój kod zawiera niespodziewany znak specjalny (<code>{{character}}<\\/code>), co sprawia, że kod jest niepoprawny.<\\/p> {{code}} <p>Czasami Twój kod może zawierać znak specjalny, który wygląda jak zwykły znak, zwłaszcza jeśli kopiujesz kod z innego programu. Spróbuj usunąć znak specjalny i wpisać do ponownie ręcznie.<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>Wygląda na to, że Twój kod zawiera niespodziewany znak specjalny (<code>{{character}}<\\/code>), co sprawia, że kod jest niepoprawny.<\\/p> {{code}} <p>Czasami Twój kod może zawierać znak specjalny, który wygląda jak zwykły znak, zwłaszcza jeśli kopiujesz kod z innego programu. Możesz spróbować zastąpić swój kod następującym kodem. Mogą być też inne miejsca, które wymagają poprawienia.<\\/p> {{suggestion}}\\n\",\"and\":\"i\",\"or\":\"lub\",\"listcomma\":\", \",\"oxfordcomma\":\"\"}}}}}<\/script>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.3"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.3"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["navigation"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/navigation-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tabsets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.21"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["default.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.21"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["6.4.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.min.css","css/v4-shims.min.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["fontawesome"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.5.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["5.5.2"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.3"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["idb-keyvalue"]},{"type":"character","attributes":{},"value":["3.2.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/idb-keyval"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["idb-keyval-iife-compat.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.11.3"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.3"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140]}},"value":[{"type":"character","attributes":{},"value":["abind","backports","base","base64enc","bit","bit64","broom","bslib","cachem","car","carData","checkmate","class","cli","codetools","colorspace","compiler","crayon","curl","data.table","datasets","dials","DiceDesign","digest","dplyr","ellipsis","evaluate","factoextra","fansi","farver","fastmap","fontawesome","foreach","furrr","future","future.apply","generics","ggplot2","ggpubr","ggrepel","ggsignif","glmnet","globals","glue","gower","GPfit","graphics","grDevices","grid","gtable","hardhat","here","highr","hms","htmltools","htmlwidgets","httpuv","infer","ipred","iterators","janeaustenr","janitor","jquerylib","jsonlite","knitr","labeling","later","lattice","lava","learnr","lhs","lifecycle","listenv","lubridate","magrittr","MASS","Matrix","methods","mime","modeldata","munsell","nnet","parallel","parallelly","parsnip","pillar","pkgconfig","png","prodlim","promises","purrr","R6","RColorBrewer","Rcpp","readr","recipes","repr","reticulate","rlang","rmarkdown","rpart","rprojroot","rsample","rstatix","rstudioapi","sass","scales","shape","shiny","skimr","snakecase","SnowballC","splines","stats","stringi","stringr","survival","tibble","tidymodels","tidyr","tidyselect","tidytext","timechange","timeDate","tokenizers","tools","tune","tzdb","utf8","utils","vctrs","vroom","withr","wordcloud","workflows","workflowsets","xfun","xtable","yaml","yardstick"]},{"type":"character","attributes":{},"value":["1.4-5","1.4.1","4.2.2","0.1-3","4.0.5","4.0.5","1.0.4","0.4.2","1.0.7","3.1-2","3.0-5","2.2.0","7.3-21","3.6.0","0.2-19","2.1-0","4.2.2","1.5.2","5.0.0","1.14.8","4.2.2","1.2.0","1.9","0.6.31","1.1.0","0.3.2","0.20","1.0.7","1.0.4","2.1.1","1.1.0","0.5.1","1.5.2","0.3.1","1.32.0","1.10.0","0.1.3","3.4.2","0.6.0","0.9.3","0.6.4","4.1-7","0.16.2","1.6.2","1.0.1","1.0-8","4.2.2","4.2.2","4.2.2","0.3.3","1.3.0","1.0.1","0.10","1.1.3","0.5.4","1.6.2","1.6.9","1.0.4","0.9-14","1.0.14","1.0.0","2.2.0","0.1.4","1.8.4","1.42","0.4.2","1.3.0","0.21-8","1.7.2.1","0.11.3","1.1.6","1.0.3","0.9.0","1.9.2","2.0.3","7.3-59","1.5-4","4.2.2","0.12","1.1.0","0.5.0","7.3-18","4.2.2","1.35.0","1.1.0","1.9.0","2.0.3","0.1-8","2023.03.31","1.2.0.1","1.0.1","2.5.1","1.1-3","1.0.10","2.1.4","1.0.6","1.1.6","1.28","1.1.0","2.21","4.1.19","2.0.3","1.1.1","0.7.2","0.14","0.4.5","1.2.1","1.4.6","1.7.4","2.1.5","0.11.0","0.7.1","4.2.2","4.2.2","1.7.12","1.5.0","3.5-5","3.2.1","1.0.0","1.3.0","1.2.0","0.4.1","0.2.0","4022.108","0.3.0","4.2.2","1.1.1","0.3.0","1.2.3","4.2.2","0.6.2","1.6.1","2.5.0","2.6","1.1.3","1.0.1","0.37","1.8-4","2.3.7","1.2.0"]}]}]}
</script>
<!--/html_preserve-->
</div>

</article> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h1 class="title toc-ignore" style="display:none;">STA 631 - Final
Project Tutorial</h1>
<h4 class="author"><em>Joseph Fahnestock</em></h4>
<h4 class="date"><em>2023-04-27</em></h4>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</main> <!-- bandContent page -->
</div> <!-- pageContent band -->



<!-- Build Tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>

</html>
